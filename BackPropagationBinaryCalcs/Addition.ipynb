{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b84f3c0d-0ef4-4786-a173-f84ae624f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f472b88-a3a4-4b8d-a53e-18e34ff70219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tools\n",
    "from sys import path\n",
    "path.append('/Users/reid/dev/PythonCode/tm/tools')\n",
    "path.append('D:/PythonCode/tm/tools')\n",
    "from tools import gen_inputs_outputs, logsig, lin, deriv_logsig, deriv_lin, e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bfddd31-1531-4b5f-9b6e-26726405aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of the network\n",
    "# Order by layers (input, layer1, layer2, ...)\n",
    "# !!! No output layer yet, wait to gen inputs\n",
    "layer_sizes = [4, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79899160-bb87-42b0-9724-442688c4fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gen inputs, outputs and size of the last layer\n",
    "inputs, outputs, S = gen_inputs_outputs(layer_sizes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbf53b7f-a7bc-44b9-82df-d9f112726b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the output layer size\n",
    "layer_sizes = np.array(layer_sizes + [S], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c1a6b04-33fd-4159-80c3-4590112d951b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 7, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Network shape\n",
    "layer_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b93dbe42-c6ff-40d8-963b-d38d7c9c6381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 1],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 1],\n",
       "       [0, 1, 1, 0],\n",
       "       [0, 1, 1, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 1],\n",
       "       [1, 0, 1, 0],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 1, 0, 0],\n",
       "       [1, 1, 0, 1],\n",
       "       [1, 1, 1, 0],\n",
       "       [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inputs\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae97cbdf-c716-48e4-ae91-3d6fab5fbc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outputs\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df41116d-c038-4df0-a8b7-bbd6672d9192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize the weights and biases randomly\n",
    "# Also create the list to store the outputs of each layer\n",
    "# Store the outptut for each layer\n",
    "# Finally create the list of the sensitivities\n",
    "weights_list = []\n",
    "biases_list = []\n",
    "n_list = []\n",
    "a_list = []\n",
    "s_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff640418-72ed-4f90-b9eb-833bc8e09cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to reset all the parameters\n",
    "# This is done to test multiple different network types\n",
    "def reset_params():\n",
    "    weights_list.clear()\n",
    "    biases_list.clear()\n",
    "    n_list.clear()\n",
    "    a_list.clear()\n",
    "    s_list.clear()\n",
    "    for i in range(1, len(layer_sizes)):\n",
    "        weights_list.append(np.random.rand(layer_sizes[i], layer_sizes[i-1]))\n",
    "        biases_list.append(np.random.rand(layer_sizes[i], 1))\n",
    "        n_list.append(np.empty((layer_sizes[i], 1), dtype=float))\n",
    "        a_list.append(np.empty((layer_sizes[i], 1), dtype=float))\n",
    "        s_list.append(np.empty((layer_sizes[i], 1), dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "040cdd31-cac6-4a10-9c96-2948d962c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transfer functions\n",
    "transfer_functions = [logsig, lin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f34b2228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vectors with the derivatives of the transfer functions\n",
    "# These need to be converted to dialation matrices\n",
    "# but this is done after the partial derivatives are calculated\n",
    "# so that the numerical values can be multiplied by the identity matrix\n",
    "# makes my life easier\n",
    "deriv_transfer_functions = [deriv_logsig, deriv_lin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "727d6d3b-bb81-41b1-a20e-79d86f88da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the output of the network\n",
    "# while also saving the data\n",
    "# Assuming that the input is already a Rx1 matrix\n",
    "def run_network(X):\n",
    "    # Get the input for the first layer so that\n",
    "    # no need to use X and can calculate\n",
    "    # recursively\n",
    "    n_list[0] = np.matmul(weights_list[0], X) + biases_list[0]\n",
    "    a_list[0] = transfer_functions[0](n_list[0])\n",
    "\n",
    "    # Calculate the rest of the outptut\n",
    "    for i in range(1, len(weights_list)):\n",
    "        n_list[i] = np.matmul(weights_list[i], a_list[i-1]) + biases_list[i]\n",
    "        a_list[i] = transfer_functions[i](n_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "430cdf1f-3c41-4f7b-8f10-7fe740c3fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the senstivites for the last layer\n",
    "# Write a function to fill the diagonal of the matrix\n",
    "def fill_F_dot(layer_num):\n",
    "    a = np.identity(len(n_list[layer_num]), float)\n",
    "    np.fill_diagonal(a, deriv_transfer_functions[layer_num](n_list[layer_num]).flatten())\n",
    "    return a\n",
    "\n",
    "def train_network(learning_rate=.1, epochs=1):\n",
    "    for i in range(epochs):\n",
    "        # Iterate through the inputs and outputs\n",
    "        for i in range(len(inputs)):\n",
    "            # Run the network\n",
    "            run_network(inputs[i].reshape(layer_sizes[0], 1))\n",
    "\n",
    "            # Get the dialation matrix for the last layer\n",
    "            F_dot = fill_F_dot(-1)\n",
    "\n",
    "            # Calculate the sensitivites for the last layer\n",
    "            s_list[-1] = -2 * np.matmul(F_dot, outputs[i].reshape(layer_sizes[-1], 1)-a_list[-1])\n",
    "\n",
    "            # Update the weights and biases for the last layer\n",
    "            weights_list[-1] += -learning_rate*np.matmul(s_list[-1], a_list[-2].T)\n",
    "            biases_list[-1] += -learning_rate*s_list[-1]\n",
    "\n",
    "            # Iterate through the remaining layers backwards\n",
    "            for i in range(len(n_list)-2, 0, -1):\n",
    "                s_list[i] = (1/layer_sizes[i+1]) * np.matmul(np.matmul(fill_F_dot(i), weights_list[i+1].T), s_list[i+1])\n",
    "                weights_list[i] += -learning_rate*np.matmul(s_list[i], a_list[i-1].T)\n",
    "                biases_list[i] += -learning_rate*s_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2795ae9-2a81-4d6d-8985-3d59af9425e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to evaluate the performance\n",
    "# of the network\n",
    "def performance():\n",
    "    results = np.empty((len(inputs), layer_sizes[-1]), dtype=float)\n",
    "    for i in range(len(inputs)):\n",
    "        run_network(inputs[i].reshape(layer_sizes[0], 1))\n",
    "        results[i] = outputs[i] - a_list[-1].flatten()\n",
    "    return e2(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e825b533-0f93-4b76-8195-415d5b3b9065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print performance\n",
    "def print_performance_dict(performance_dict):\n",
    "    for a in sorted(performance_dict.items(), key=lambda x: x[1]):\n",
    "        print(f'Error: {a[1]} | ' + a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac7602d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains netowrk using the parameters for each bit size\n",
    "def update_performance_dict(layer_sizes_list, performance_dict):\n",
    "    for layer_sizes in layer_sizes_list:\n",
    "        # Get the inputs and outputs for the specifiq network size\n",
    "        inputs, outputs, S = gen_inputs_outputs(layer_sizes[0])\n",
    "        layer_sizes.append(S)\n",
    "    \n",
    "        # Iterate through the different learning rates\n",
    "        # and epochs\n",
    "        for rate in learning_rates:\n",
    "            for epochs in epochs_list:\n",
    "                # Reset weights and biases\n",
    "                reset_params()\n",
    "                # Train the network\n",
    "                train_network(learning_rate=rate, epochs=epochs)\n",
    "                # Update the performance dict\n",
    "                performance_dict.update({f'Layers: {layer_sizes}, Learning rate: {rate}, Epochs: {epochs}': performance()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60afa525-7577-458f-b6e3-8a4cf362b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "### !!! Do not run code underneath until saving to the file\n",
    "### It trains 22000 different networks\n",
    "# Performance dictionnaries of the network\n",
    "performance_dict_2bits = {}\n",
    "performance_dict_4bits = {}\n",
    "performance_dict_8bits = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "957eb418-c39e-4a66-9023-4af7573462b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters that won't change despite differnt layer sizes\n",
    "# Set different learning rates\n",
    "learning_rates = [1/(16*(2**i)) for i in range(10)]\n",
    "\n",
    "# Set the diffrent epochs\n",
    "epochs_list = [i for i in range(1, 21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48a0e709",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Multiple different layer sizes\n",
    "# Start with 1 hidden layer\n",
    "layer_sizes_list_2bits = [[4, 2*(2**i)]for i in range(10)]\n",
    "layer_sizes_list_4bits = [[8, 2*(2**i)]for i in range(10)]\n",
    "layer_sizes_list_8bits = [[16, 2*(2**i)]for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d0f0575-efb5-4c96-85df-fc0e1450e68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance for 1 hidden layer\n",
    "# 2 bits\n",
    "update_performance_dict(layer_sizes_list_2bits, performance_dict_2bits)\n",
    "# 4 bits\n",
    "update_performance_dict(layer_sizes_list_4bits, performance_dict_4bits)\n",
    "# 8 bits\n",
    "update_performance_dict(layer_sizes_list_8bits, performance_dict_8bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c10735f5-04b3-4432-8436-af626574fe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Hidden layers\n",
    "# Redefine the transfer functions\n",
    "transfer_functions = [logsig, logsig, lin]\n",
    "deriv_transfer_functions = [deriv_logsig, deriv_logsig, deriv_lin]\n",
    "\n",
    "# New layer sizes\n",
    "layer_sizes_list_2bits = [[4, 2*(2**i), 2*(2**j)] for j in range(10) for i in range(10)]\n",
    "layer_sizes_list_4bits = [[8, 2*(2**i), 2*(2**j)] for j in range(10) for i in range(10)]\n",
    "layer_sizes_list_8bits = [[16, 2*(2**i), 2*(2**j)] for j in range(10) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f90dadf-2fc3-49be-a7c8-4248f4b59ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the performance for 2 hidden layers\n",
    "# 2 bits\n",
    "update_performance_dict(layer_sizes_list_2bits, performance_dict_2bits)\n",
    "# 4 bits\n",
    "update_performance_dict(layer_sizes_list_4bits, performance_dict_4bits)\n",
    "# 8 bits\n",
    "update_performance_dict(layer_sizes_list_8bits, performance_dict_8bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df991ea-5884-49ee-b418-1e9edd3e688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*7 + '2bits' + '-'*7)\n",
    "print_performance_dict(performance_dict_2bits)\n",
    "print('-'*7 + '4bits' + '-'*7)\n",
    "print_performance_dict(performance_dict_4bits)\n",
    "print('-'*7 + '8bits' + '-'*7)\n",
    "print_performance_dict(performance_dict_8bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb685cf8-803e-450a-a063-e21cdd3fc840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data of the performance dicts\n",
    "performance_dicts = [performance_dict_2bits, performance_dict_4bits, performance_dict_8bits]\n",
    "for i in range(len(performance_dicts)):\n",
    "    with open(f'/Users/reid/dev/PythonCode/tm/BackPropagationBinaryCalcs/data/{2**(i+1)}bit_performance.txt', 'w') as f:\n",
    "        f.write('parameters,performance\\n')\n",
    "        f.writelines([f'{x}\\n' for x in sorted(list(performance_dicts[i].items()), key=lambda x: x[1], reverse=True)])\n",
    "### You can run code below this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2379fd6e-0469-46dc-9b68-d910b7c469bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chose a few networks from the data file to run tests on\n",
    "# General parameters\n",
    "learning_rates = [0.001953125, 0.00390625, 0.0078125]\n",
    "epochs_list = [12, 15, 17, 5, 14, 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3934c577-4e55-4162-b10e-39b5740597da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with one hidden layer\n",
    "transfer_functions = [logsig, lin]\n",
    "deriv_transfer_functions = [deriv_logsig, deriv_lin]\n",
    "\n",
    "layer_sizes_list_2bits = [\n",
    "    [4, 2],\n",
    "    [4, 32],\n",
    "    [4, 64],\n",
    "]\n",
    "layer_sizes_list_4bits = [\n",
    "    [8, 64],\n",
    "    [8, 2],\n",
    "    [8, 1024],\n",
    "]\n",
    "layer_sizes_list_8bits = [\n",
    "    [16, 16],\n",
    "    [16, 64],\n",
    "    [16, 4],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e87e10-d95d-42b8-8073-6e2e0cee87e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to calculate the average performance\n",
    "def update_average_performance_dict(layer_sizes_list, average_performance_dict, n_samples):\n",
    "    for layer_sizes in layer_sizes_list:\n",
    "        inputs, outputs, S = gen_inputs_outputs(layer_sizes[0])\n",
    "        layer_sizes.append(S)\n",
    "\n",
    "        cumulated_performance = 0\n",
    "        \n",
    "        for rate in learning_rates:\n",
    "                for epochs in epochs_list:\n",
    "                    for i in range(n_samples):\n",
    "                        reset_params()\n",
    "                        train_network(learning_rate=rate, epochs=epochs)\n",
    "                        cumulated_performance += performance()\n",
    "                        \n",
    "                    average_performance_dict.update({f'Layers: {layer_sizes}, Learning rate: {rate}, Epochs: {epochs}': cumulated_performance/n_samples})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc88c856-fd54-430b-8889-fec8af69db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_performance_dict_2bits = {}\n",
    "average_performance_dict_4bits = {}\n",
    "average_performance_dict_8bits = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df65e5-bae1-47e5-814a-0cc1d73b5511",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_average_performance_dict(layer_sizes_list_2bits, average_performance_dict_2bits, 100)\n",
    "update_average_performance_dict(layer_sizes_list_4bits, average_performance_dict_4bits, 100)\n",
    "update_average_performance_dict(layer_sizes_list_8bits, average_performance_dict_8bits, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fdb65c-6136-442b-8ccd-0f45f7daa461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two hidden layers\n",
    "transfer_functions = [logsig, logsig, lin]\n",
    "deriv_transfer_functions = [deriv_logsig, deriv_logsig, deriv_lin]\n",
    "\n",
    "layer_sizes_list_2bits = [\n",
    "    [4, 8, 2],\n",
    "    [4, 2, 128],\n",
    "    [4, 256, 32],\n",
    "]\n",
    "layer_sizes_list_4bits = [\n",
    "    [8, 32, 64],\n",
    "    [8, 1024, 64],\n",
    "    [8, 2, 256],\n",
    "]\n",
    "layer_sizes_list_8bits = [\n",
    "    [16, 8, 8],\n",
    "    [16, 2, 1024],\n",
    "    [16, 16, 4],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8214975-888b-47c6-a8b1-023ff536c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_average_performance_dict(layer_sizes_list_2bits, average_performance_dict_2bits, 100)\n",
    "update_average_performance_dict(layer_sizes_list_4bits, average_performance_dict_4bits, 100)\n",
    "update_average_performance_dict(layer_sizes_list_8bits, average_performance_dict_8bits, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f42f99-ecc1-4622-bbac-6ef2ae645b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----------2 bit average----------')\n",
    "print_performance_dict(average_performance_dict_2bits)\n",
    "print('----------4 bit average----------')\n",
    "print_performance_dict(average_performance_dict_4bits)\n",
    "print('----------8 bit average----------')\n",
    "print_performance_dict(average_performance_dict_8bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf111c91-cfaf-4293-b004-0b1b0014e768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the average performance data\n",
    "performance_dicts = [average_performance_dict_2bits, average_performance_dict_4bits, average_performance_dict_8bits]\n",
    "for i in range(len(performance_dicts)):\n",
    "    with open(f'./data/{2**(i+1)}bit_average_performance.txt', 'w') as f:\n",
    "        f.write('parameters,performance\\n')\n",
    "        f.writelines([f'{x}\\n' for x in sorted(list(performance_dicts[i].items()), key=lambda x: x[1], reverse=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0ca12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the average data goes by steps for each network\n",
    "from csv import reader\n",
    "\n",
    "with open ('./data/8bit_average_performance.txt', 'r') as f:\n",
    "    csv_reader = reader(f, delimiter=',')\n",
    "    network_params =  []\n",
    "    \n",
    "    skip = True\n",
    "    for row in csv_reader:\n",
    "        if skip: skip = False; continue\n",
    "        \n",
    "        if len(row)==6:\n",
    "            network_params.append({'layers': row[0]+row[1]+row[2], 'lr': row[3], 'epochs': row[4], 'error': float(row[5][1:-1])})\n",
    "        \n",
    "        if len(row)==7:\n",
    "            network_params.append({'layers': row[0]+row[1]+row[2]+row[3], 'lr': row[4], 'epochs': row[5], 'error': float(row[6][1:-1])})\n",
    "    \n",
    "    for i in range(0, len(network_params), 6):\n",
    "        layers_steps = [network_params[i]['layers'], \n",
    "                       network_params[i+1]['layers'], \n",
    "                       network_params[i+2]['layers'], \n",
    "                       network_params[i+3]['layers'], \n",
    "                       network_params[i+4]['layers'],\n",
    "                       network_params[i+5]['layers']]\n",
    "        \n",
    "        epochs_steps = [network_params[i]['epochs'], \n",
    "                       network_params[i+1]['epochs'], \n",
    "                       network_params[i+2]['epochs'], \n",
    "                       network_params[i+3]['epochs'], \n",
    "                       network_params[i+4]['epochs'],\n",
    "                       network_params[i+5]['epochs']]\n",
    "        \n",
    "        lr_steps = [network_params[i]['lr'], \n",
    "                       network_params[i+1]['lr'], \n",
    "                       network_params[i+2]['lr'], \n",
    "                       network_params[i+3]['lr'], \n",
    "                       network_params[i+4]['lr'],\n",
    "                       network_params[i+5]['lr']]\n",
    "        \n",
    "        err_steps = [round(network_params[i]['error']), \n",
    "                       round(network_params[i+1]['error']), \n",
    "                       round(network_params[i+2]['error']), \n",
    "                       round(network_params[i+3]['error']), \n",
    "                       round(network_params[i+4]['error']),\n",
    "                       round(network_params[i+5]['error'])]\n",
    "        \n",
    "        print(f'Step from index {i}')\n",
    "        \n",
    "        if len(layers_steps) == len(set(layers_steps)):\n",
    "            print('All layers in step unique')\n",
    "        \n",
    "        if 1 == len(set(epochs_steps)):\n",
    "            print('All epochs in step unique')\n",
    "            \n",
    "        if 1 == len(set(lr_steps)):\n",
    "            print('All lr in step unique')\n",
    "        \n",
    "        if 1 == len(set(err_steps)):\n",
    "            print('All err within round')\n",
    "        else: print(set(err_steps))\n",
    "            \n",
    "        print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ac04ca1e-3c6b-40af-b6b7-99cb032265f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: test extremely simplified network structures see beneath as well\n",
    "# TODO: test an extremely complexe network structure (just a lot of layers)\n",
    "# TODO: test stable network for whole range of epochs and record results\n",
    "# TODO: test stable network performance on hard lim transfer functions\n",
    "# TODO: test stable network performance but training it with a hardlim transfer function last layer\n",
    "# TODO: redo all this with symetrical network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "26a62729-863e-4263-8d9c-4d66e90bc36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test performance on an extremely simple network structure\n",
    "# Network parameters\n",
    "R = 4\n",
    "layer_sizes = [4, 8, 2]\n",
    "deriv_transfer_functions = [deriv_logsig, deriv_lin]\n",
    "# Inputs and outputs\n",
    "inputs, outputs, S = gen_inputs_outputs(R)\n",
    "layer_sizes = np.array(layer_sizes + [S], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "34b03a57-3b04-4a24-844e-a6c5cc655fd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m reset_params()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_network\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.001953125\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(performance())\n",
      "Cell \u001b[0;32mIn[20], line 13\u001b[0m, in \u001b[0;36mtrain_network\u001b[0;34m(learning_rate, epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Iterate through the inputs and outputs\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs)):\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;66;03m# Run the network\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m         \u001b[43mrun_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_sizes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m# Get the dialation matrix for the last layer\u001b[39;00m\n\u001b[1;32m     16\u001b[0m         F_dot \u001b[38;5;241m=\u001b[39m fill_F_dot(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 14\u001b[0m, in \u001b[0;36mrun_network\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(weights_list)):\n\u001b[1;32m     13\u001b[0m     n_list[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmatmul(weights_list[i], a_list[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m+\u001b[39m biases_list[i]\n\u001b[0;32m---> 14\u001b[0m     a_list[i] \u001b[38;5;241m=\u001b[39m \u001b[43mtransfer_functions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m(n_list[i])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "reset_params()\n",
    "train_network(0.001953125, epochs=12)\n",
    "print(performance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bd1f488c-f7ce-4248-9ad2-cc572723d087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test performance on an extremely complexe network structure\n",
    "# Network parameters\n",
    "R = 4\n",
    "layer_sizes = [4, 1024, 1024, 1024, 1024]\n",
    "transfer_functions = [logsig, logsig, logsig, logsig, lin]\n",
    "deriv_transfer_functions = [deriv_logsig, deriv_logsig, deriv_logsig, deriv_logsig, deriv_lin]\n",
    "# Inputs and outputs\n",
    "inputs, outputs, S = gen_inputs_outputs(R)\n",
    "layer_sizes = np.array(layer_sizes + [S], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "92dfc2b5-c9df-4bf2-bcd8-e6cda2fdd5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2955718257616284e+190\n"
     ]
    }
   ],
   "source": [
    "reset_params()\n",
    "train_network(0.001953125, epochs=12)\n",
    "print(performance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5649a34f-a7ad-463a-9402-b72e5a9e3c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18f00e57-ffe2-4019-befa-371b308d4aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(layer_sizes[1], input_shape=(layer_sizes[0],), activation='sigmoid'))\n",
    "model.add(Dense(layer_sizes[2], activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1461c9e-d5ff-46f6-bf5d-d3d912900cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.5000 - loss: 7.0425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1672a4dd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdg = SGD(.9)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=sdg,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "model.fit(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94cda203-692a-464f-a3e4-0ef7c23a265e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.01186371, -8.282264  , -1.4656483 ],\n",
       "       [ 0.0887537 , -9.469966  , -1.5549538 ],\n",
       "       [ 0.15937938, -8.323184  , -1.3819622 ],\n",
       "       [ 0.22767666, -9.4916    , -1.4718292 ],\n",
       "       [-0.01628557, -8.611647  , -1.6199257 ],\n",
       "       [ 0.04203045, -9.72632   , -1.6907108 ],\n",
       "       [ 0.14307892, -8.662352  , -1.5352875 ],\n",
       "       [ 0.20412186, -9.765932  , -1.603532  ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tm",
   "language": "python",
   "name": "tm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
