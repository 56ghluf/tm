{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b84f3c0d-0ef4-4786-a173-f84ae624f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f472b88-a3a4-4b8d-a53e-18e34ff70219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tools\n",
    "from sys import path\n",
    "path.append('/Users/reid/dev/PythonCode/tm/tools')\n",
    "path.append('D:/PythonCode/tm/tools')\n",
    "from tools import gen_inputs_outputs, logsig, lin, deriv_logsig, deriv_lin, e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bfddd31-1531-4b5f-9b6e-26726405aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of the network\n",
    "# Order by layers (input, layer1, layer2, ...)\n",
    "# !!! No output layer yet, wait to gen inputs\n",
    "layer_sizes = [4, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79899160-bb87-42b0-9724-442688c4fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gen inputs, outputs and size of the last layer\n",
    "inputs, outputs, S = gen_inputs_outputs(layer_sizes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbf53b7f-a7bc-44b9-82df-d9f112726b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the output layer size\n",
    "layer_sizes = np.array(layer_sizes + [S], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c1a6b04-33fd-4159-80c3-4590112d951b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 7, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Network shape\n",
    "layer_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b93dbe42-c6ff-40d8-963b-d38d7c9c6381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 1],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 1],\n",
       "       [0, 1, 1, 0],\n",
       "       [0, 1, 1, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 1],\n",
       "       [1, 0, 1, 0],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 1, 0, 0],\n",
       "       [1, 1, 0, 1],\n",
       "       [1, 1, 1, 0],\n",
       "       [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inputs\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae97cbdf-c716-48e4-ae91-3d6fab5fbc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outputs\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df41116d-c038-4df0-a8b7-bbd6672d9192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize the weights and biases randomly\n",
    "# Also create the list to store the outputs of each layer\n",
    "# Store the outptut for each layer\n",
    "# Finally create the list of the sensitivities\n",
    "weights_list = []\n",
    "biases_list = []\n",
    "n_list = []\n",
    "a_list = []\n",
    "s_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff640418-72ed-4f90-b9eb-833bc8e09cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to reset all the parameters\n",
    "# This is done to test multiple different network types\n",
    "def reset_params():\n",
    "    weights_list.clear()\n",
    "    biases_list.clear()\n",
    "    n_list.clear()\n",
    "    a_list.clear()\n",
    "    s_list.clear()\n",
    "    for i in range(1, len(layer_sizes)):\n",
    "        weights_list.append(np.random.rand(layer_sizes[i], layer_sizes[i-1]))\n",
    "        biases_list.append(np.random.rand(layer_sizes[i], 1))\n",
    "        n_list.append(np.empty((layer_sizes[i], 1), dtype=float))\n",
    "        a_list.append(np.empty((layer_sizes[i], 1), dtype=float))\n",
    "        s_list.append(np.empty((layer_sizes[i], 1), dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "040cdd31-cac6-4a10-9c96-2948d962c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transfer functions\n",
    "transfer_functions = [logsig, lin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f34b2228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vectors with the derivatives of the transfer functions\n",
    "# These need to be converted to dialation matrices\n",
    "# but this is done after the partial derivatives are calculated\n",
    "# so that the numerical values can be multiplied by the identity matrix\n",
    "# makes my life easier\n",
    "deriv_transfer_functions = [deriv_logsig, deriv_lin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "727d6d3b-bb81-41b1-a20e-79d86f88da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the output of the network\n",
    "# while also saving the data\n",
    "# Assuming that the input is already a Rx1 matrix\n",
    "def run_network(X):\n",
    "    # Get the input for the first layer so that\n",
    "    # no need to use X and can calculate\n",
    "    # recursively\n",
    "    n_list[0] = np.matmul(weights_list[0], X) + biases_list[0]\n",
    "    a_list[0] = transfer_functions[0](n_list[0])\n",
    "\n",
    "    # Calculate the rest of the outptut\n",
    "    for i in range(1, len(weights_list)):\n",
    "        n_list[i] = np.matmul(weights_list[i], a_list[i-1]) + biases_list[i]\n",
    "        a_list[i] = transfer_functions[i](n_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "430cdf1f-3c41-4f7b-8f10-7fe740c3fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the senstivites for the last layer\n",
    "# Write a function to fill the diagonal of the matrix\n",
    "def fill_F_dot(layer_num):\n",
    "    a = np.identity(len(n_list[layer_num]), float)\n",
    "    np.fill_diagonal(a, deriv_transfer_functions[layer_num](n_list[layer_num]).flatten())\n",
    "    return a\n",
    "\n",
    "def train_network(learning_rate=.1, epochs=1):\n",
    "    for i in range(epochs):\n",
    "        # Iterate through the inputs and outputs\n",
    "        for i in range(len(inputs)):\n",
    "            # Run the network\n",
    "            run_network(inputs[i].reshape(layer_sizes[0], 1))\n",
    "\n",
    "            # Get the dialation matrix for the last layer\n",
    "            F_dot = fill_F_dot(-1)\n",
    "\n",
    "            # Calculate the sensitivites for the last layer\n",
    "            s_list[-1] = -2 * np.matmul(F_dot, outputs[i].reshape(layer_sizes[-1], 1)-a_list[-1])\n",
    "\n",
    "            # Update the weights and biases for the last layer\n",
    "            weights_list[-1] += -learning_rate*np.matmul(s_list[-1], a_list[-2].T)\n",
    "            biases_list[-1] += -learning_rate*s_list[-1]\n",
    "\n",
    "            # Iterate through the remaining layers backwards\n",
    "            for i in range(len(n_list)-2, 0, -1):\n",
    "                s_list[i] = (1/layer_sizes[i+1]) * np.matmul(np.matmul(fill_F_dot(i), weights_list[i+1].T), s_list[i+1])\n",
    "                weights_list[i] += -learning_rate*np.matmul(s_list[i], a_list[i-1].T)\n",
    "                biases_list[i] += -learning_rate*s_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2795ae9-2a81-4d6d-8985-3d59af9425e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to evaluate the performance\n",
    "# of the network\n",
    "def performance():\n",
    "    results = np.empty((len(inputs), layer_sizes[-1]), dtype=float)\n",
    "    for i in range(len(inputs)):\n",
    "        run_network(inputs[i].reshape(layer_sizes[0], 1))\n",
    "        results[i] = outputs[i] - a_list[-1].flatten()\n",
    "    return e2(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e825b533-0f93-4b76-8195-415d5b3b9065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print performance\n",
    "def print_performance_dict(performance_dict):\n",
    "    for a in sorted(performance_dict.items(), key=lambda x: x[1]):\n",
    "        print(f'Error: {a[1]} | ' + a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac7602d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains netowrk using the parameters for each bit size\n",
    "def update_performance_dict(layer_sizes_list, performance_dict):\n",
    "    for layer_sizes in layer_sizes_list:\n",
    "        # Get the inputs and outputs for the specifiq network size\n",
    "        inputs, outputs, S = gen_inputs_outputs(layer_sizes[0])\n",
    "        layer_sizes.append(S)\n",
    "    \n",
    "        # Iterate through the different learning rates\n",
    "        # and epochs\n",
    "        for rate in learning_rates:\n",
    "            for epochs in epochs_list:\n",
    "                # Reset weights and biases\n",
    "                reset_params()\n",
    "                # Train the network\n",
    "                train_network(learning_rate=rate, epochs=epochs)\n",
    "                # Update the performance dict\n",
    "                performance_dict.update({f'Layers: {layer_sizes}, Learning rate: {rate}, Epochs: {epochs}': performance()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60afa525-7577-458f-b6e3-8a4cf362b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "### !!! Do not run code underneath until saving to the file\n",
    "### It trains 22000 different networks\n",
    "# Performance dictionnaries of the network\n",
    "performance_dict_2bits = {}\n",
    "performance_dict_4bits = {}\n",
    "performance_dict_8bits = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "957eb418-c39e-4a66-9023-4af7573462b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters that won't change despite differnt layer sizes\n",
    "# Set different learning rates\n",
    "learning_rates = [1/(16*(2**i)) for i in range(10)]\n",
    "\n",
    "# Set the diffrent epochs\n",
    "epochs_list = [i for i in range(1, 21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48a0e709",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Multiple different layer sizes\n",
    "# Start with 1 hidden layer\n",
    "layer_sizes_list_2bits = [[4, 2*(2**i)]for i in range(10)]\n",
    "layer_sizes_list_4bits = [[8, 2*(2**i)]for i in range(10)]\n",
    "layer_sizes_list_8bits = [[16, 2*(2**i)]for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d0f0575-efb5-4c96-85df-fc0e1450e68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance for 1 hidden layer\n",
    "# 2 bits\n",
    "update_performance_dict(layer_sizes_list_2bits, performance_dict_2bits)\n",
    "# 4 bits\n",
    "update_performance_dict(layer_sizes_list_4bits, performance_dict_4bits)\n",
    "# 8 bits\n",
    "update_performance_dict(layer_sizes_list_8bits, performance_dict_8bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c10735f5-04b3-4432-8436-af626574fe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Hidden layers\n",
    "# Redefine the transfer functions\n",
    "transfer_functions = [logsig, logsig, lin]\n",
    "deriv_transfer_functions = [deriv_logsig, deriv_logsig, deriv_lin]\n",
    "\n",
    "# New layer sizes\n",
    "layer_sizes_list_2bits = [[4, 2*(2**i), 2*(2**j)] for j in range(10) for i in range(10)]\n",
    "layer_sizes_list_4bits = [[8, 2*(2**i), 2*(2**j)] for j in range(10) for i in range(10)]\n",
    "layer_sizes_list_8bits = [[16, 2*(2**i), 2*(2**j)] for j in range(10) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f90dadf-2fc3-49be-a7c8-4248f4b59ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the performance for 2 hidden layers\n",
    "# 2 bits\n",
    "update_performance_dict(layer_sizes_list_2bits, performance_dict_2bits)\n",
    "# 4 bits\n",
    "update_performance_dict(layer_sizes_list_4bits, performance_dict_4bits)\n",
    "# 8 bits\n",
    "update_performance_dict(layer_sizes_list_8bits, performance_dict_8bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7df991ea-5884-49ee-b418-1e9edd3e688c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('-'*7 + '2bits' + '-'*7)\n",
    "print_performance_dict(performance_dict_2bits)\n",
    "print('-'*7 + '4bits' + '-'*7)\n",
    "print_performance_dict(performance_dict_4bits)\n",
    "print('-'*7 + '8bits' + '-'*7)\n",
    "print_performance_dict(performance_dict_8bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb685cf8-803e-450a-a063-e21cdd3fc840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data of the performance dicts\n",
    "performance_dicts = [performance_dict_2bits, performance_dict_4bits, performance_dict_8bits]\n",
    "for i in range(len(performance_dicts)):\n",
    "    with open(f'/Users/reid/dev/PythonCode/tm/BackPropagationBinaryCalcs/data/{2**(i+1)}bit_performance.txt', 'w') as f:\n",
    "        f.write('parameters,performance\\n')\n",
    "        f.writelines([f'{x}\\n' for x in sorted(list(performance_dicts[i].items()), key=lambda x: x[1], reverse=True)])\n",
    "### You can run code below this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2379fd6e-0469-46dc-9b68-d910b7c469bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chose a few networks from the data file to run tests on\n",
    "# General parameters\n",
    "learning_rates = [0.001953125, 0.00390625, 0.0078125]\n",
    "epochs_list = [12, 15, 17, 5, 14, 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3934c577-4e55-4162-b10e-39b5740597da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with one hidden layer\n",
    "transfer_functions = [logsig, lin]\n",
    "deriv_transfer_functions = [deriv_logsig, deriv_lin]\n",
    "\n",
    "layer_sizes_list_2bits = [\n",
    "    [4, 2],\n",
    "    [4, 32],\n",
    "    [4, 64],\n",
    "]\n",
    "layer_sizes_list_4bits = [\n",
    "    [8, 64],\n",
    "    [8, 2],\n",
    "    [8, 1024],\n",
    "]\n",
    "layer_sizes_list_8bits = [\n",
    "    [16, 16],\n",
    "    [16, 64],\n",
    "    [16, 4],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9e87e10-d95d-42b8-8073-6e2e0cee87e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to calculate the average performance\n",
    "def update_average_performance_dict(layer_sizes_list, average_performance_dict, n_samples):\n",
    "    for layer_sizes in layer_sizes_list:\n",
    "        inputs, outputs, S = gen_inputs_outputs(layer_sizes[0])\n",
    "        layer_sizes.append(S)\n",
    "\n",
    "        cumulated_performance = 0\n",
    "        \n",
    "        for rate in learning_rates:\n",
    "                for epochs in epochs_list:\n",
    "                    for i in range(n_samples):\n",
    "                        reset_params()\n",
    "                        train_network(learning_rate=rate, epochs=epochs)\n",
    "                        cumulated_performance += performance()\n",
    "                        \n",
    "                    average_performance_dict.update({f'Layers: {layer_sizes}, Learning rate: {rate}, Epochs: {epochs}': cumulated_performance/n_samples})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc88c856-fd54-430b-8889-fec8af69db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_performance_dict_2bits = {}\n",
    "average_performance_dict_4bits = {}\n",
    "average_performance_dict_8bits = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8df65e5-bae1-47e5-814a-0cc1d73b5511",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_average_performance_dict(layer_sizes_list_2bits, average_performance_dict_2bits, 500)\n",
    "update_average_performance_dict(layer_sizes_list_4bits, average_performance_dict_4bits, 500)\n",
    "update_average_performance_dict(layer_sizes_list_8bits, average_performance_dict_8bits, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69fdb65c-6136-442b-8ccd-0f45f7daa461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two hidden layers\n",
    "transfer_functions = [logsig, logsig, lin]\n",
    "deriv_transfer_functions = [deriv_logsig, deriv_logsig, deriv_lin]\n",
    "\n",
    "layer_sizes_list_2bits = [\n",
    "    [4, 8, 2],\n",
    "    [4, 2, 128],\n",
    "    [4, 256, 32],\n",
    "]\n",
    "layer_sizes_list_4bits = [\n",
    "    [8, 32, 64],\n",
    "    [8, 1024, 64],\n",
    "    [8, 2, 256],\n",
    "]\n",
    "layer_sizes_list_8bits = [\n",
    "    [16, 8, 8],\n",
    "    [16, 2, 1024],\n",
    "    [16, 16, 4],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8214975-888b-47c6-a8b1-023ff536c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_average_performance_dict(layer_sizes_list_2bits, average_performance_dict_2bits, 500)\n",
    "update_average_performance_dict(layer_sizes_list_4bits, average_performance_dict_4bits, 500)\n",
    "update_average_performance_dict(layer_sizes_list_8bits, average_performance_dict_8bits, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4f42f99-ecc1-4622-bbac-6ef2ae645b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------2 bit average----------\n",
      "Error: 11.479299935406559 | Layers: [4, 2, 3], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 11.53308861576714 | Layers: [4, 64, 3], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 11.542363713634707 | Layers: [4, 32, 3], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 17.803159669594926 | Layers: [4, 256, 32, 3], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 17.81829355607529 | Layers: [4, 8, 2, 3], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 17.8565476440209 | Layers: [4, 2, 128, 3], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 22.912720139622905 | Layers: [4, 2, 3], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 22.932651544335705 | Layers: [4, 32, 3], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 22.959130223979894 | Layers: [4, 64, 3], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 34.038750350235546 | Layers: [4, 256, 32, 3], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 34.04837897686988 | Layers: [4, 8, 2, 3], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 34.11924538239579 | Layers: [4, 2, 128, 3], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 34.28332421740538 | Layers: [4, 2, 3], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 34.31304517781144 | Layers: [4, 32, 3], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 34.35375151780721 | Layers: [4, 64, 3], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 49.36942675626122 | Layers: [4, 256, 32, 3], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 49.38338423215539 | Layers: [4, 8, 2, 3], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 49.52280423092537 | Layers: [4, 2, 128, 3], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 58.60442767862088 | Layers: [4, 2, 3], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 58.66639067788805 | Layers: [4, 32, 3], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 58.933351599465986 | Layers: [4, 64, 3], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 70.0275682740699 | Layers: [4, 2, 3], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 70.089178783494 | Layers: [4, 32, 3], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 70.38063486676334 | Layers: [4, 64, 3], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 70.98568308373444 | Layers: [4, 256, 32, 3], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 70.99059953993759 | Layers: [4, 8, 2, 3], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 71.14545888182603 | Layers: [4, 2, 128, 3], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 81.39286545906315 | Layers: [4, 2, 3], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 81.47058875756592 | Layers: [4, 32, 3], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 81.76174797041534 | Layers: [4, 64, 3], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 87.76474027182607 | Layers: [4, 8, 2, 3], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 87.77751840108593 | Layers: [4, 256, 32, 3], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 87.8332995522739 | Layers: [4, 2, 128, 3], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 92.79722139419324 | Layers: [4, 2, 3], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 92.89517344214096 | Layers: [4, 32, 3], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 93.18855003677086 | Layers: [4, 64, 3], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 102.282125241387 | Layers: [4, 256, 32, 3], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 102.32003885677472 | Layers: [4, 8, 2, 3], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 102.39766605362973 | Layers: [4, 2, 128, 3], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 104.20002494696524 | Layers: [4, 2, 3], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 104.32266576587459 | Layers: [4, 32, 3], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 104.58721422613664 | Layers: [4, 64, 3], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 115.46415607919238 | Layers: [4, 256, 32, 3], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 115.50099414504072 | Layers: [4, 8, 2, 3], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 115.55574033935808 | Layers: [4, 2, 128, 3], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 115.60413676218269 | Layers: [4, 2, 3], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 115.70691812415889 | Layers: [4, 32, 3], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 115.99897084846954 | Layers: [4, 64, 3], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 127.5493452660428 | Layers: [4, 2, 3], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 127.64881278518982 | Layers: [4, 32, 3], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 127.81120370609823 | Layers: [4, 256, 32, 3], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 127.84318478986899 | Layers: [4, 8, 2, 3], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 127.90506834685497 | Layers: [4, 2, 128, 3], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 127.94775853931539 | Layers: [4, 64, 3], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 138.96037980835303 | Layers: [4, 2, 3], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 139.06233686133976 | Layers: [4, 32, 3], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 139.3655311354261 | Layers: [4, 64, 3], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 139.89600284771336 | Layers: [4, 256, 32, 3], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 139.9271685143888 | Layers: [4, 8, 2, 3], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 139.99754040526437 | Layers: [4, 2, 128, 3], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 150.3503629924623 | Layers: [4, 2, 3], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 150.464779124257 | Layers: [4, 32, 3], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 150.77549497196236 | Layers: [4, 64, 3], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 158.8047501555472 | Layers: [4, 256, 32, 3], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 158.9052246893548 | Layers: [4, 8, 2, 3], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 158.96001959048374 | Layers: [4, 2, 128, 3], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 161.94966983426502 | Layers: [4, 2, 3], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 162.0416430199122 | Layers: [4, 32, 3], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 162.35469431245951 | Layers: [4, 64, 3], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 171.35647901250198 | Layers: [4, 256, 32, 3], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 171.44777136646732 | Layers: [4, 8, 2, 3], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 171.49304809809826 | Layers: [4, 2, 128, 3], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 173.51408040157574 | Layers: [4, 2, 3], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 173.578183403458 | Layers: [4, 32, 3], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 173.91250825668513 | Layers: [4, 64, 3], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 183.30553497292775 | Layers: [4, 256, 32, 3], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 183.3976909174778 | Layers: [4, 8, 2, 3], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 183.43931897480365 | Layers: [4, 2, 128, 3], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 185.0585143209214 | Layers: [4, 2, 3], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 185.09990408752645 | Layers: [4, 32, 3], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 185.42613607161735 | Layers: [4, 64, 3], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 195.1549796568752 | Layers: [4, 256, 32, 3], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 195.24287826939462 | Layers: [4, 8, 2, 3], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 195.29777870463082 | Layers: [4, 2, 128, 3], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 196.710943225851 | Layers: [4, 2, 3], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 196.75924577022224 | Layers: [4, 32, 3], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 197.08214169115206 | Layers: [4, 64, 3], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 206.96112834115237 | Layers: [4, 256, 32, 3], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 207.05459673490415 | Layers: [4, 8, 2, 3], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 207.1076393886222 | Layers: [4, 2, 128, 3], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 208.27056520035603 | Layers: [4, 2, 3], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 208.34494129472404 | Layers: [4, 32, 3], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 208.6346419566883 | Layers: [4, 64, 3], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 218.76045861016956 | Layers: [4, 256, 32, 3], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 218.8532848480475 | Layers: [4, 8, 2, 3], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 218.90263379050754 | Layers: [4, 2, 128, 3], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 219.78574695468245 | Layers: [4, 2, 3], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 219.8635009094866 | Layers: [4, 32, 3], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 220.18452393120222 | Layers: [4, 64, 3], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 233.0850677036304 | Layers: [4, 8, 2, 3], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 233.08830334790446 | Layers: [4, 256, 32, 3], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 233.12210536783402 | Layers: [4, 2, 128, 3], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 244.9059357665249 | Layers: [4, 8, 2, 3], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 244.90616359199507 | Layers: [4, 256, 32, 3], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 244.94082879821235 | Layers: [4, 2, 128, 3], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 256.68882680502713 | Layers: [4, 8, 2, 3], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 256.697979751098 | Layers: [4, 256, 32, 3], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 256.72922640644714 | Layers: [4, 2, 128, 3], Learning rate: 0.0078125, Epochs: 19\n",
      "----------4 bit average----------\n",
      "Error: 11.52125189229209 | Layers: [8, 64, 5], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 11.529966064774994 | Layers: [8, 2, 5], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 11.54941888052693 | Layers: [8, 1024, 5], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 17.734936751169116 | Layers: [8, 2, 256, 5], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 17.771136106818137 | Layers: [8, 32, 64, 5], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 17.797082005190408 | Layers: [8, 1024, 64, 5], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 22.93545220618611 | Layers: [8, 64, 5], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 22.967776082842366 | Layers: [8, 1024, 5], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 22.97390924094255 | Layers: [8, 2, 5], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 33.9142398007065 | Layers: [8, 2, 256, 5], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 34.02771311133692 | Layers: [8, 32, 64, 5], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 34.0577817867141 | Layers: [8, 1024, 64, 5], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 34.33294623164111 | Layers: [8, 2, 5], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 34.342261239293606 | Layers: [8, 64, 5], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 34.36963960349433 | Layers: [8, 1024, 5], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 49.16614492913895 | Layers: [8, 2, 256, 5], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 49.30209267643317 | Layers: [8, 32, 64, 5], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 49.30811814748233 | Layers: [8, 1024, 64, 5], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 58.8935957989017 | Layers: [8, 64, 5], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 58.92504531710621 | Layers: [8, 1024, 5], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 58.92637827094051 | Layers: [8, 2, 5], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 70.33838708906141 | Layers: [8, 64, 5], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 70.34968421794851 | Layers: [8, 1024, 5], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 70.35456700750983 | Layers: [8, 2, 5], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 70.75109544335368 | Layers: [8, 2, 256, 5], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 70.92238149223809 | Layers: [8, 1024, 64, 5], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 70.9801946945552 | Layers: [8, 32, 64, 5], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 81.71487172990274 | Layers: [8, 1024, 5], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 81.73138779396906 | Layers: [8, 2, 5], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 81.73276581717343 | Layers: [8, 64, 5], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 87.45131816332153 | Layers: [8, 2, 256, 5], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 87.64727811343163 | Layers: [8, 1024, 64, 5], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 87.77962378772474 | Layers: [8, 32, 64, 5], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 93.16559847966866 | Layers: [8, 64, 5], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 93.16735236149115 | Layers: [8, 1024, 5], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 93.16793356747601 | Layers: [8, 2, 5], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 101.95391871353873 | Layers: [8, 2, 256, 5], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 102.12386575454849 | Layers: [8, 1024, 64, 5], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 102.32648289307448 | Layers: [8, 32, 64, 5], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 104.56231391663331 | Layers: [8, 2, 5], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 104.57953900759362 | Layers: [8, 64, 5], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 104.5912005731964 | Layers: [8, 1024, 5], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 115.15006359436191 | Layers: [8, 2, 256, 5], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 115.31792874164447 | Layers: [8, 1024, 64, 5], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 115.50659368202157 | Layers: [8, 32, 64, 5], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 115.96445134595727 | Layers: [8, 2, 5], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 115.98371984429534 | Layers: [8, 1024, 5], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 115.99184023453832 | Layers: [8, 64, 5], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 127.49785347806456 | Layers: [8, 2, 256, 5], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 127.68401177851294 | Layers: [8, 1024, 64, 5], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 127.85026875555734 | Layers: [8, 32, 64, 5], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 127.89329930074541 | Layers: [8, 2, 5], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 127.9115630263835 | Layers: [8, 1024, 5], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 127.93042731351137 | Layers: [8, 64, 5], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 139.33035150933895 | Layers: [8, 2, 5], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 139.34028327238815 | Layers: [8, 1024, 5], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 139.34149537812715 | Layers: [8, 64, 5], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 139.598433391289 | Layers: [8, 2, 256, 5], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 139.7723689118355 | Layers: [8, 1024, 64, 5], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 139.93606760841266 | Layers: [8, 32, 64, 5], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 150.74368235413826 | Layers: [8, 2, 5], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 150.7526768603052 | Layers: [8, 1024, 5], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 150.75320844138386 | Layers: [8, 64, 5], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 158.5939875705992 | Layers: [8, 2, 256, 5], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 158.71044413383007 | Layers: [8, 1024, 64, 5], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 158.9317545005911 | Layers: [8, 32, 64, 5], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 162.33520600838006 | Layers: [8, 1024, 5], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 162.3383316396165 | Layers: [8, 2, 5], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 162.34599436499627 | Layers: [8, 64, 5], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 171.15776322108368 | Layers: [8, 2, 256, 5], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 171.2657461547688 | Layers: [8, 1024, 64, 5], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 171.4830373484535 | Layers: [8, 32, 64, 5], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 173.88947728970027 | Layers: [8, 1024, 5], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 173.89076122305877 | Layers: [8, 2, 5], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 173.9050209233364 | Layers: [8, 64, 5], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 183.10458432058851 | Layers: [8, 2, 256, 5], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 183.21914795447057 | Layers: [8, 1024, 64, 5], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 183.42720014823547 | Layers: [8, 32, 64, 5], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 185.42621551269244 | Layers: [8, 2, 5], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 185.4284149542269 | Layers: [8, 64, 5], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 185.4323196829548 | Layers: [8, 1024, 5], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 194.95538876258487 | Layers: [8, 2, 256, 5], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 195.05903235367205 | Layers: [8, 1024, 64, 5], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 195.275598005952 | Layers: [8, 32, 64, 5], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 197.03751255324067 | Layers: [8, 64, 5], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 197.0431127978376 | Layers: [8, 2, 5], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 197.08387850590506 | Layers: [8, 1024, 5], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 206.7612545246967 | Layers: [8, 2, 256, 5], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 206.8670815335989 | Layers: [8, 1024, 64, 5], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 207.08461447212383 | Layers: [8, 32, 64, 5], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 208.59677859991683 | Layers: [8, 2, 5], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 208.61371589331148 | Layers: [8, 64, 5], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 208.64525776165507 | Layers: [8, 1024, 5], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 218.56331690251739 | Layers: [8, 2, 256, 5], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 218.66608802522924 | Layers: [8, 1024, 64, 5], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 218.8789714003368 | Layers: [8, 32, 64, 5], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 220.12947615097198 | Layers: [8, 2, 5], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 220.14211661729527 | Layers: [8, 64, 5], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 220.16636267713912 | Layers: [8, 1024, 5], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 232.85971870271743 | Layers: [8, 2, 256, 5], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 232.89934585821504 | Layers: [8, 1024, 64, 5], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 233.15487654353532 | Layers: [8, 32, 64, 5], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 244.6760387752481 | Layers: [8, 2, 256, 5], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 244.71748787139848 | Layers: [8, 1024, 64, 5], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 244.97056714409715 | Layers: [8, 32, 64, 5], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 256.4619644506755 | Layers: [8, 2, 256, 5], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 256.51416381096794 | Layers: [8, 1024, 64, 5], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 256.75921084746534 | Layers: [8, 32, 64, 5], Learning rate: 0.0078125, Epochs: 19\n",
      "----------8 bit average----------\n",
      "Error: 11.521229323451546 | Layers: [16, 64, 9], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 11.533691838686963 | Layers: [16, 4, 9], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 11.538710909627994 | Layers: [16, 16, 9], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 17.84394381019967 | Layers: [16, 16, 4, 9], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 17.892382095197604 | Layers: [16, 2, 1024, 9], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 17.897902692752506 | Layers: [16, 8, 8, 9], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 22.949767029753932 | Layers: [16, 16, 9], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 22.95176305201178 | Layers: [16, 64, 9], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 22.952783934111224 | Layers: [16, 4, 9], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 33.97633224616584 | Layers: [16, 16, 4, 9], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 34.08411727811276 | Layers: [16, 2, 1024, 9], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 34.15260251822005 | Layers: [16, 8, 8, 9], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 34.34165779423593 | Layers: [16, 4, 9], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 34.3442153155857 | Layers: [16, 64, 9], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 34.36595163827496 | Layers: [16, 16, 9], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 49.28336841395545 | Layers: [16, 16, 4, 9], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 49.396544823757026 | Layers: [16, 2, 1024, 9], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 49.4489833308342 | Layers: [16, 8, 8, 9], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 58.68838125557738 | Layers: [16, 4, 9], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 58.80934774776554 | Layers: [16, 16, 9], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 58.91206852390396 | Layers: [16, 64, 9], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 70.11343576668179 | Layers: [16, 4, 9], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 70.2554625238196 | Layers: [16, 16, 9], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 70.36119427676782 | Layers: [16, 64, 9], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 70.92250712725581 | Layers: [16, 16, 4, 9], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 70.9721325666301 | Layers: [16, 2, 1024, 9], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 71.15471631591988 | Layers: [16, 8, 8, 9], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 81.51131188130972 | Layers: [16, 4, 9], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 81.65699891004438 | Layers: [16, 16, 9], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 81.73315252184724 | Layers: [16, 64, 9], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 87.6445441072507 | Layers: [16, 16, 4, 9], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 87.69530566472521 | Layers: [16, 2, 1024, 9], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 87.90420644231963 | Layers: [16, 8, 8, 9], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 92.94985489126626 | Layers: [16, 4, 9], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 93.10357719598046 | Layers: [16, 16, 9], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 93.14276049392916 | Layers: [16, 64, 9], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 102.14690257462254 | Layers: [16, 16, 4, 9], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 102.24230579000525 | Layers: [16, 2, 1024, 9], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 102.48498699438424 | Layers: [16, 8, 8, 9], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 104.37016647523073 | Layers: [16, 4, 9], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 104.53827591826948 | Layers: [16, 16, 9], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 104.56137859455133 | Layers: [16, 64, 9], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 115.3301841532724 | Layers: [16, 16, 4, 9], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 115.41718583278373 | Layers: [16, 2, 1024, 9], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 115.65289089939871 | Layers: [16, 8, 8, 9], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 115.7750964873406 | Layers: [16, 4, 9], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 115.93554178009686 | Layers: [16, 16, 9], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 115.96603880823984 | Layers: [16, 64, 9], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 127.69793780364805 | Layers: [16, 16, 4, 9], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 127.73135871675842 | Layers: [16, 4, 9], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 127.76865061334682 | Layers: [16, 2, 1024, 9], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 127.88616699662077 | Layers: [16, 16, 9], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 127.89927159650483 | Layers: [16, 64, 9], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 127.9894712293931 | Layers: [16, 8, 8, 9], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 139.155662600671 | Layers: [16, 4, 9], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 139.30047754274102 | Layers: [16, 16, 9], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 139.31166755256427 | Layers: [16, 64, 9], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 139.7871351519717 | Layers: [16, 16, 4, 9], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 139.8654304661464 | Layers: [16, 2, 1024, 9], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 140.09032624521876 | Layers: [16, 8, 8, 9], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 150.56283082757702 | Layers: [16, 4, 9], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 150.70670167950115 | Layers: [16, 64, 9], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 150.70930907282533 | Layers: [16, 16, 9], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 158.71444239661776 | Layers: [16, 16, 4, 9], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 158.74620393624025 | Layers: [16, 2, 1024, 9], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 159.00720699850308 | Layers: [16, 8, 8, 9], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 162.1415780417807 | Layers: [16, 4, 9], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 162.25700736522091 | Layers: [16, 64, 9], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 162.28626284906977 | Layers: [16, 16, 9], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 171.25531407261107 | Layers: [16, 16, 4, 9], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 171.30158470173595 | Layers: [16, 2, 1024, 9], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 171.56217117012466 | Layers: [16, 8, 8, 9], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 173.69471502792342 | Layers: [16, 4, 9], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 173.7933712471991 | Layers: [16, 64, 9], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 173.82660236454387 | Layers: [16, 16, 9], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 183.20654294044434 | Layers: [16, 16, 4, 9], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 183.25433386616618 | Layers: [16, 2, 1024, 9], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 183.51240831735487 | Layers: [16, 8, 8, 9], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 185.23407496806226 | Layers: [16, 4, 9], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 185.3213370114951 | Layers: [16, 64, 9], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 185.34611772625107 | Layers: [16, 16, 9], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 195.0500124634933 | Layers: [16, 16, 4, 9], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 195.09699690073913 | Layers: [16, 2, 1024, 9], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 195.35945847445805 | Layers: [16, 8, 8, 9], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 196.87599335419625 | Layers: [16, 4, 9], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 196.97616873293012 | Layers: [16, 64, 9], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 196.9936408102921 | Layers: [16, 16, 9], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 206.85867192690642 | Layers: [16, 16, 4, 9], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 206.9091004805013 | Layers: [16, 2, 1024, 9], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 207.16143911811727 | Layers: [16, 8, 8, 9], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 208.4488562618683 | Layers: [16, 4, 9], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 208.53760114669166 | Layers: [16, 64, 9], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 208.57041568550474 | Layers: [16, 16, 9], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 218.65750835379973 | Layers: [16, 16, 4, 9], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 218.71361268256558 | Layers: [16, 2, 1024, 9], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 218.960900198967 | Layers: [16, 8, 8, 9], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 219.99025416238172 | Layers: [16, 4, 9], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 220.04443344359504 | Layers: [16, 64, 9], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 220.09630097405383 | Layers: [16, 16, 9], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 232.91196578365566 | Layers: [16, 16, 4, 9], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 232.96017903141293 | Layers: [16, 2, 1024, 9], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 233.2478435373495 | Layers: [16, 8, 8, 9], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 244.7329663853673 | Layers: [16, 16, 4, 9], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 244.77259000372746 | Layers: [16, 2, 1024, 9], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 245.0663715486289 | Layers: [16, 8, 8, 9], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 256.52539348656046 | Layers: [16, 16, 4, 9], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 256.56037012506084 | Layers: [16, 2, 1024, 9], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 256.85776392782293 | Layers: [16, 8, 8, 9], Learning rate: 0.0078125, Epochs: 19\n"
     ]
    }
   ],
   "source": [
    "print('----------2 bit average----------')\n",
    "print_performance_dict(average_performance_dict_2bits)\n",
    "print('----------4 bit average----------')\n",
    "print_performance_dict(average_performance_dict_4bits)\n",
    "print('----------8 bit average----------')\n",
    "print_performance_dict(average_performance_dict_8bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf111c91-cfaf-4293-b004-0b1b0014e768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the average performance data\n",
    "performance_dicts = [average_performance_dict_2bits, average_performance_dict_4bits, average_performance_dict_8bits]\n",
    "for i in range(len(performance_dicts)):\n",
    "    with open(f'./data/{2**(i+1)}bit_average_performance.txt', 'w') as f:\n",
    "        f.write('parameters,performance\\n')\n",
    "        f.writelines([f'{x}\\n' for x in sorted(list(performance_dicts[i].items()), key=lambda x: x[1], reverse=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c0ca12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step from index 0\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 3\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 6\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 9\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 12\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 15\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "{208, 209}\n",
      "-----------------------------------\n",
      "Step from index 18\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 21\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 24\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 27\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 30\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "{184, 183}\n",
      "-----------------------------------\n",
      "Step from index 33\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 36\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "{171, 172}\n",
      "-----------------------------------\n",
      "Step from index 39\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 42\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 45\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 48\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 51\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 54\n",
      "All layers in step the unique\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 57\n",
      "All layers in step the unique\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 60\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 63\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "{115, 116}\n",
      "-----------------------------------\n",
      "Step from index 66\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "{104, 105}\n",
      "-----------------------------------\n",
      "Step from index 69\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 72\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 75\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 78\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 81\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 84\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 87\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 90\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 93\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 96\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 99\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 102\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 105\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check whether the average data goes by steps for each network\n",
    "from csv import reader\n",
    "\n",
    "with open ('./data/8bit_average_performance.txt', 'r') as f:\n",
    "    csv_reader = reader(f, delimiter=',')\n",
    "    network_params =  []\n",
    "    \n",
    "    skip = True\n",
    "    for row in csv_reader:\n",
    "        if skip: skip = False; continue\n",
    "        \n",
    "        if len(row)==6:\n",
    "            network_params.append({'layers': row[0]+row[1]+row[2], 'lr': row[3], 'epochs': row[4], 'error': float(row[5][1:-1])})\n",
    "        \n",
    "        if len(row)==7:\n",
    "            network_params.append({'layers': row[0]+row[1]+row[2]+row[3], 'lr': row[4], 'epochs': row[5], 'error': float(row[6][1:-1])})\n",
    "    \n",
    "    for i in range(0, len(network_params), 3):\n",
    "        layers_steps = [network_params[i]['layers'], \n",
    "                       network_params[i+1]['layers'], \n",
    "                       network_params[i+2]['layers']]\n",
    "        \n",
    "        epochs_steps = [network_params[i]['epochs'], \n",
    "                       network_params[i+1]['epochs'], \n",
    "                       network_params[i+2]['epochs']]\n",
    "        \n",
    "        lr_steps = [network_params[i]['lr'], \n",
    "                       network_params[i+1]['lr'], \n",
    "                       network_params[i+2]['lr']]\n",
    "        \n",
    "        err_steps = [round(network_params[i]['error']), \n",
    "                       round(network_params[i+1]['error']), \n",
    "                       round(network_params[i+2]['error'])]\n",
    "        \n",
    "        print(f'Step from index {i}')\n",
    "        \n",
    "        if len(layers_steps) == len(set(layers_steps)):\n",
    "            print('All layers in step the unique')\n",
    "        \n",
    "        if 1 == len(set(epochs_steps)):\n",
    "            print('All epochs in step the same')\n",
    "            \n",
    "        if 1 == len(set(lr_steps)):\n",
    "            print('All lr in step the same')\n",
    "        \n",
    "        if 1 == len(set(err_steps)):\n",
    "            print('All err within round')\n",
    "        else: print(set(err_steps))\n",
    "            \n",
    "        print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ac04ca1e-3c6b-40af-b6b7-99cb032265f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: test stable network for whole range of epochs and record results\n",
    "# TODO: test extremely simplified network structures see beneath as well\n",
    "# TODO: test an extremely complexe network structure (just a lot of layers)\n",
    "# TODO: test stable network performance on hard lim transfer functions\n",
    "# TODO: test stable network performance but training it with a hardlim transfer function last layer\n",
    "# TODO: redo all this with symetrical network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26a62729-863e-4263-8d9c-4d66e90bc36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test network on huge number of diffrent epochs\n",
    "# Network parameters\n",
    "R = 4\n",
    "layer_sizes = [4, 2]\n",
    "deriv_transfer_functions = [deriv_logsig, deriv_lin]\n",
    "# Inputs and outputs\n",
    "inputs, outputs, S = gen_inputs_outputs(R)\n",
    "layer_sizes = np.array(layer_sizes + [S], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34b03a57-3b04-4a24-844e-a6c5cc655fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Error: 47.99503850595259\n",
      "Epochs: 2 | Error: 39.78278774135901\n",
      "Epochs: 3 | Error: 27.635026460168895\n",
      "Epochs: 4 | Error: 20.721169857816186\n",
      "Epochs: 5 | Error: 19.545244679748222\n",
      "Epochs: 6 | Error: 21.309221923001715\n",
      "Epochs: 7 | Error: 20.32644989389195\n",
      "Epochs: 8 | Error: 15.15387496643299\n",
      "Epochs: 9 | Error: 15.12047325512602\n",
      "Epochs: 10 | Error: 13.695153316912915\n",
      "Epochs: 11 | Error: 12.546516173426655\n",
      "Epochs: 12 | Error: 12.845741997839328\n",
      "Epochs: 13 | Error: 11.865051025070368\n",
      "Epochs: 14 | Error: 12.060221067313885\n",
      "Epochs: 15 | Error: 12.375805150994736\n",
      "Epochs: 16 | Error: 12.282177209884178\n",
      "Epochs: 17 | Error: 11.946533116519097\n",
      "Epochs: 18 | Error: 11.665741292151505\n",
      "Epochs: 19 | Error: 11.968232400803176\n",
      "Epochs: 20 | Error: 11.674588279944588\n",
      "Epochs: 21 | Error: 11.629389114960706\n",
      "Epochs: 22 | Error: 11.511764694714818\n",
      "Epochs: 23 | Error: 11.471902449678018\n",
      "Epochs: 24 | Error: 11.952847691937246\n",
      "Epochs: 25 | Error: 11.432386393321266\n",
      "Epochs: 26 | Error: 11.617161399055416\n",
      "Epochs: 27 | Error: 11.845053323840144\n",
      "Epochs: 28 | Error: 11.317747414841833\n",
      "Epochs: 29 | Error: 11.495487279800129\n",
      "Epochs: 30 | Error: 11.692898264618588\n",
      "Epochs: 31 | Error: 11.325512535760478\n",
      "Epochs: 32 | Error: 11.622768311483073\n",
      "Epochs: 33 | Error: 11.308749113743156\n",
      "Epochs: 34 | Error: 11.10980054115934\n",
      "Epochs: 35 | Error: 11.532131047336648\n",
      "Epochs: 36 | Error: 11.552563162660974\n",
      "Epochs: 37 | Error: 11.192651475196925\n",
      "Epochs: 38 | Error: 10.831329121402579\n",
      "Epochs: 39 | Error: 11.551292979636944\n",
      "Epochs: 40 | Error: 11.915085795900161\n",
      "Epochs: 41 | Error: 11.100055290673946\n",
      "Epochs: 42 | Error: 11.450469281434337\n",
      "Epochs: 43 | Error: 11.959940672641956\n",
      "Epochs: 44 | Error: 11.237210560185092\n",
      "Epochs: 45 | Error: 11.715511454638005\n",
      "Epochs: 46 | Error: 11.44445296990475\n",
      "Epochs: 47 | Error: 10.81666974217563\n",
      "Epochs: 48 | Error: 11.2240973401467\n",
      "Epochs: 49 | Error: 11.165523547998427\n",
      "Epochs: 50 | Error: 10.91036234688973\n",
      "Epochs: 51 | Error: 11.456939953419857\n",
      "Epochs: 52 | Error: 11.603905086013713\n",
      "Epochs: 53 | Error: 11.686351659928818\n",
      "Epochs: 54 | Error: 11.288904608209549\n",
      "Epochs: 55 | Error: 11.260232641075605\n",
      "Epochs: 56 | Error: 11.427357646951025\n",
      "Epochs: 57 | Error: 11.504644490039862\n",
      "Epochs: 58 | Error: 11.357587773797121\n",
      "Epochs: 59 | Error: 11.501113142603542\n",
      "Epochs: 60 | Error: 11.428022707626296\n",
      "Epochs: 61 | Error: 11.49423978233179\n",
      "Epochs: 62 | Error: 11.447252000984204\n",
      "Epochs: 63 | Error: 11.354583591090877\n",
      "Epochs: 64 | Error: 11.384876022111552\n",
      "Epochs: 65 | Error: 11.276784724217693\n",
      "Epochs: 66 | Error: 11.233767277691971\n",
      "Epochs: 67 | Error: 11.734510154138036\n",
      "Epochs: 68 | Error: 11.708679993093172\n",
      "Epochs: 69 | Error: 11.106381546845133\n",
      "Epochs: 70 | Error: 11.280810504218419\n",
      "Epochs: 71 | Error: 11.563434564751145\n",
      "Epochs: 72 | Error: 11.695139488502978\n",
      "Epochs: 73 | Error: 11.31360954134938\n",
      "Epochs: 74 | Error: 11.257462168896122\n",
      "Epochs: 75 | Error: 11.719736205448015\n",
      "Epochs: 76 | Error: 11.339521011633455\n",
      "Epochs: 77 | Error: 11.342982501512447\n",
      "Epochs: 78 | Error: 11.48116032138476\n",
      "Epochs: 79 | Error: 11.539961534223826\n",
      "Epochs: 80 | Error: 11.100802730151251\n",
      "Epochs: 81 | Error: 11.579196646021714\n",
      "Epochs: 82 | Error: 11.28127527545704\n",
      "Epochs: 83 | Error: 11.37578092255464\n",
      "Epochs: 84 | Error: 11.466734906371274\n",
      "Epochs: 85 | Error: 11.31361648801835\n",
      "Epochs: 86 | Error: 11.402912143233186\n",
      "Epochs: 87 | Error: 11.411419041766404\n",
      "Epochs: 88 | Error: 11.78117262120832\n",
      "Epochs: 89 | Error: 11.547194132191995\n",
      "Epochs: 90 | Error: 11.728788996791051\n",
      "Epochs: 91 | Error: 11.676829257335799\n",
      "Epochs: 92 | Error: 11.47594070930559\n",
      "Epochs: 93 | Error: 11.22276172747079\n",
      "Epochs: 94 | Error: 11.432437967717064\n",
      "Epochs: 95 | Error: 11.488240529325635\n",
      "Epochs: 96 | Error: 11.40757216238086\n",
      "Epochs: 97 | Error: 11.199993586245977\n",
      "Epochs: 98 | Error: 11.175992683391286\n",
      "Epochs: 99 | Error: 11.462509670501836\n",
      "Epochs: 100 | Error: 11.728764447025394\n",
      "Epochs: 101 | Error: 11.564344346249714\n",
      "Epochs: 102 | Error: 11.505309720603698\n",
      "Epochs: 103 | Error: 11.154226599327286\n",
      "Epochs: 104 | Error: 11.50418882122401\n",
      "Epochs: 105 | Error: 11.229717329441927\n",
      "Epochs: 106 | Error: 11.435554366877938\n",
      "Epochs: 107 | Error: 11.714408813856409\n",
      "Epochs: 108 | Error: 11.579435904231195\n",
      "Epochs: 109 | Error: 11.313698458627371\n",
      "Epochs: 110 | Error: 10.951024456970552\n",
      "Epochs: 111 | Error: 11.577750680139669\n",
      "Epochs: 112 | Error: 11.452372959728882\n",
      "Epochs: 113 | Error: 11.406482258472597\n",
      "Epochs: 114 | Error: 11.268538891851833\n",
      "Epochs: 115 | Error: 11.395903115713898\n",
      "Epochs: 116 | Error: 11.43244927919942\n",
      "Epochs: 117 | Error: 11.428697104382785\n",
      "Epochs: 118 | Error: 11.278785417217392\n",
      "Epochs: 119 | Error: 11.576827669282928\n",
      "Epochs: 120 | Error: 10.874862859648657\n",
      "Epochs: 121 | Error: 11.576734109525475\n",
      "Epochs: 122 | Error: 11.479388772383805\n",
      "Epochs: 123 | Error: 11.566859513891922\n",
      "Epochs: 124 | Error: 11.237035354069427\n",
      "Epochs: 125 | Error: 11.430211887736334\n",
      "Epochs: 126 | Error: 11.146245516602926\n",
      "Epochs: 127 | Error: 11.29487116939355\n",
      "Epochs: 128 | Error: 11.430361336058523\n",
      "Epochs: 129 | Error: 11.397756726024209\n",
      "Epochs: 130 | Error: 11.347934401479721\n",
      "Epochs: 131 | Error: 11.597357257614691\n",
      "Epochs: 132 | Error: 11.629693610701596\n",
      "Epochs: 133 | Error: 10.915056763324465\n",
      "Epochs: 134 | Error: 11.498832713847694\n",
      "Epochs: 135 | Error: 11.376556406698148\n",
      "Epochs: 136 | Error: 10.943393957459056\n",
      "Epochs: 137 | Error: 10.882009769599286\n",
      "Epochs: 138 | Error: 11.568230087008962\n",
      "Epochs: 139 | Error: 11.493118313163516\n",
      "Epochs: 140 | Error: 10.828516411632098\n",
      "Epochs: 141 | Error: 11.39528280328141\n",
      "Epochs: 142 | Error: 11.245841003164456\n",
      "Epochs: 143 | Error: 11.134192951380742\n",
      "Epochs: 144 | Error: 11.075359938998062\n",
      "Epochs: 145 | Error: 11.047329015426053\n",
      "Epochs: 146 | Error: 11.103498006284866\n",
      "Epochs: 147 | Error: 11.194503996654174\n",
      "Epochs: 148 | Error: 11.126875751495625\n",
      "Epochs: 149 | Error: 11.34499106516352\n",
      "Epochs: 150 | Error: 11.171340411043678\n",
      "Epochs: 151 | Error: 11.617365464018532\n",
      "Epochs: 152 | Error: 11.481712969710363\n",
      "Epochs: 153 | Error: 11.404860132368956\n",
      "Epochs: 154 | Error: 11.034484297866326\n",
      "Epochs: 155 | Error: 11.669360918370407\n",
      "Epochs: 156 | Error: 11.109094987898594\n",
      "Epochs: 157 | Error: 11.652258435637172\n",
      "Epochs: 158 | Error: 11.293694599592934\n",
      "Epochs: 159 | Error: 10.917415062752315\n",
      "Epochs: 160 | Error: 11.603793428559095\n",
      "Epochs: 161 | Error: 11.316887454327707\n",
      "Epochs: 162 | Error: 11.57300229412169\n",
      "Epochs: 163 | Error: 11.490329238050668\n",
      "Epochs: 164 | Error: 11.051108900179761\n",
      "Epochs: 165 | Error: 11.523636053499832\n",
      "Epochs: 166 | Error: 11.138583693917981\n",
      "Epochs: 167 | Error: 11.687092763783056\n",
      "Epochs: 168 | Error: 11.157501339058694\n",
      "Epochs: 169 | Error: 11.561844139289278\n",
      "Epochs: 170 | Error: 11.31282722651895\n",
      "Epochs: 171 | Error: 11.400199678215365\n",
      "Epochs: 172 | Error: 11.283415257962707\n",
      "Epochs: 173 | Error: 11.157719948278867\n",
      "Epochs: 174 | Error: 11.713300501618638\n",
      "Epochs: 175 | Error: 11.114902283822035\n",
      "Epochs: 176 | Error: 11.24391262398551\n",
      "Epochs: 177 | Error: 11.18075135351738\n",
      "Epochs: 178 | Error: 11.310673747009607\n",
      "Epochs: 179 | Error: 11.36057718131345\n",
      "Epochs: 180 | Error: 11.077423817837683\n",
      "Epochs: 181 | Error: 11.002100078107402\n",
      "Epochs: 182 | Error: 11.359601884817037\n",
      "Epochs: 183 | Error: 11.64030101054599\n",
      "Epochs: 184 | Error: 10.901578775280845\n",
      "Epochs: 185 | Error: 11.503320263515029\n",
      "Epochs: 186 | Error: 11.050040666493699\n",
      "Epochs: 187 | Error: 11.500561139209054\n",
      "Epochs: 188 | Error: 11.344371446841118\n",
      "Epochs: 189 | Error: 11.49926889581608\n",
      "Epochs: 190 | Error: 11.48234074365126\n",
      "Epochs: 191 | Error: 11.431652169840333\n",
      "Epochs: 192 | Error: 11.26178760296427\n",
      "Epochs: 193 | Error: 11.14511537052493\n",
      "Epochs: 194 | Error: 11.44795039651382\n",
      "Epochs: 195 | Error: 10.904390861565911\n",
      "Epochs: 196 | Error: 11.026186337268536\n",
      "Epochs: 197 | Error: 11.450444145317887\n",
      "Epochs: 198 | Error: 11.18137417834916\n",
      "Epochs: 199 | Error: 11.434124371799443\n",
      "Epochs: 200 | Error: 11.054390227953345\n",
      "Epochs: 201 | Error: 11.167030450512712\n",
      "Epochs: 202 | Error: 11.22015963180168\n",
      "Epochs: 203 | Error: 11.19298860853406\n",
      "Epochs: 204 | Error: 11.308429254848761\n",
      "Epochs: 205 | Error: 11.503811076240071\n",
      "Epochs: 206 | Error: 11.158243221221365\n",
      "Epochs: 207 | Error: 11.378695907003896\n",
      "Epochs: 208 | Error: 11.32678877841585\n",
      "Epochs: 209 | Error: 11.554212950676918\n",
      "Epochs: 210 | Error: 11.121159685190085\n",
      "Epochs: 211 | Error: 10.893823071103089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 212 | Error: 11.43724333038814\n",
      "Epochs: 213 | Error: 11.09389777422646\n",
      "Epochs: 214 | Error: 11.590481533256646\n",
      "Epochs: 215 | Error: 11.388530985445433\n",
      "Epochs: 216 | Error: 11.198445094596561\n",
      "Epochs: 217 | Error: 10.78588924210465\n",
      "Epochs: 218 | Error: 10.970298003175463\n",
      "Epochs: 219 | Error: 11.534767607664254\n",
      "Epochs: 220 | Error: 11.537854462844967\n",
      "Epochs: 221 | Error: 11.392932666308266\n",
      "Epochs: 222 | Error: 11.187779705193885\n",
      "Epochs: 223 | Error: 11.164942386396469\n",
      "Epochs: 224 | Error: 11.104534992353933\n",
      "Epochs: 225 | Error: 11.485716818557023\n",
      "Epochs: 226 | Error: 11.506565259818142\n",
      "Epochs: 227 | Error: 11.255691111710592\n",
      "Epochs: 228 | Error: 11.056812544506219\n",
      "Epochs: 229 | Error: 11.39553693844814\n",
      "Epochs: 230 | Error: 11.046962732552375\n",
      "Epochs: 231 | Error: 11.432237575297895\n",
      "Epochs: 232 | Error: 11.261017227192408\n",
      "Epochs: 233 | Error: 11.585411880712101\n",
      "Epochs: 234 | Error: 11.331679154758325\n",
      "Epochs: 235 | Error: 11.377453087665629\n",
      "Epochs: 236 | Error: 11.094131810557716\n",
      "Epochs: 237 | Error: 11.659467284120796\n",
      "Epochs: 238 | Error: 11.331274811010687\n",
      "Epochs: 239 | Error: 11.56443477852851\n",
      "Epochs: 240 | Error: 11.09554738086974\n",
      "Epochs: 241 | Error: 10.975047772368047\n",
      "Epochs: 242 | Error: 11.395770212373478\n",
      "Epochs: 243 | Error: 11.28204631280032\n",
      "Epochs: 244 | Error: 11.698428370175074\n",
      "Epochs: 245 | Error: 11.293653927144726\n",
      "Epochs: 246 | Error: 11.178712969643682\n",
      "Epochs: 247 | Error: 11.265503233146532\n",
      "Epochs: 248 | Error: 11.363492376489136\n",
      "Epochs: 249 | Error: 11.070263258776437\n",
      "Epochs: 250 | Error: 11.107073886527253\n",
      "Epochs: 251 | Error: 11.397400938671037\n",
      "Epochs: 252 | Error: 10.943764431389637\n",
      "Epochs: 253 | Error: 11.096631643087012\n",
      "Epochs: 254 | Error: 11.286213431159592\n",
      "Epochs: 255 | Error: 11.05994583276757\n",
      "Epochs: 256 | Error: 11.30546076104446\n",
      "Epochs: 257 | Error: 11.400257273264131\n",
      "Epochs: 258 | Error: 10.950031011474715\n",
      "Epochs: 259 | Error: 11.081987246215105\n",
      "Epochs: 260 | Error: 11.543007212286357\n",
      "Epochs: 261 | Error: 11.41634370543489\n",
      "Epochs: 262 | Error: 11.417104316024421\n",
      "Epochs: 263 | Error: 11.127758626461969\n",
      "Epochs: 264 | Error: 11.074610124507478\n",
      "Epochs: 265 | Error: 11.0113946012676\n",
      "Epochs: 266 | Error: 11.180011265640065\n",
      "Epochs: 267 | Error: 11.35793323777716\n",
      "Epochs: 268 | Error: 11.391076703680646\n",
      "Epochs: 269 | Error: 10.97461915033848\n",
      "Epochs: 270 | Error: 11.312720164408965\n",
      "Epochs: 271 | Error: 11.128589562065478\n",
      "Epochs: 272 | Error: 10.841704462180548\n",
      "Epochs: 273 | Error: 11.239109785413333\n",
      "Epochs: 274 | Error: 10.953592237366593\n",
      "Epochs: 275 | Error: 11.44348797911506\n",
      "Epochs: 276 | Error: 11.100761511738684\n",
      "Epochs: 277 | Error: 11.178959818679747\n",
      "Epochs: 278 | Error: 10.700516968888016\n",
      "Epochs: 279 | Error: 11.156370245280417\n",
      "Epochs: 280 | Error: 11.103730371107837\n",
      "Epochs: 281 | Error: 10.932717351547023\n",
      "Epochs: 282 | Error: 11.277384271303404\n",
      "Epochs: 283 | Error: 11.212757089051316\n",
      "Epochs: 284 | Error: 11.08326689100444\n",
      "Epochs: 285 | Error: 11.67687937591122\n",
      "Epochs: 286 | Error: 11.544405225721292\n",
      "Epochs: 287 | Error: 11.227888841560109\n",
      "Epochs: 288 | Error: 11.305962543346775\n",
      "Epochs: 289 | Error: 11.369085591162507\n",
      "Epochs: 290 | Error: 11.224554874525884\n",
      "Epochs: 291 | Error: 11.098231176791645\n",
      "Epochs: 292 | Error: 10.79484663409661\n",
      "Epochs: 293 | Error: 11.092327702743452\n",
      "Epochs: 294 | Error: 11.325101073217994\n",
      "Epochs: 295 | Error: 11.169857796820613\n",
      "Epochs: 296 | Error: 10.8317574125435\n",
      "Epochs: 297 | Error: 10.718320252846105\n",
      "Epochs: 298 | Error: 11.024017297187317\n",
      "Epochs: 299 | Error: 11.33970663848091\n",
      "Epochs: 300 | Error: 10.91149776408496\n",
      "Epochs: 301 | Error: 11.231681943502352\n",
      "Epochs: 302 | Error: 11.557184255160664\n",
      "Epochs: 303 | Error: 11.374224147275202\n",
      "Epochs: 304 | Error: 10.789652702737976\n",
      "Epochs: 305 | Error: 11.11763859572352\n",
      "Epochs: 306 | Error: 11.163478751554406\n",
      "Epochs: 307 | Error: 11.55360001836898\n",
      "Epochs: 308 | Error: 11.408202682498972\n",
      "Epochs: 309 | Error: 11.351543556781316\n",
      "Epochs: 310 | Error: 11.55181909917294\n",
      "Epochs: 311 | Error: 11.345207803666653\n",
      "Epochs: 312 | Error: 10.877637012402301\n",
      "Epochs: 313 | Error: 11.325226791961182\n",
      "Epochs: 314 | Error: 11.213203977918903\n",
      "Epochs: 315 | Error: 11.641728519565367\n",
      "Epochs: 316 | Error: 11.287085359339693\n",
      "Epochs: 317 | Error: 11.434538104142197\n",
      "Epochs: 318 | Error: 10.875325785898045\n",
      "Epochs: 319 | Error: 11.128791657142301\n",
      "Epochs: 320 | Error: 10.987947618638817\n",
      "Epochs: 321 | Error: 10.671415530096459\n",
      "Epochs: 322 | Error: 10.504113683145725\n",
      "Epochs: 323 | Error: 10.857223249038935\n",
      "Epochs: 324 | Error: 10.947108610698132\n",
      "Epochs: 325 | Error: 11.327977678532019\n",
      "Epochs: 326 | Error: 11.248024918809753\n",
      "Epochs: 327 | Error: 11.030563539322056\n",
      "Epochs: 328 | Error: 10.984165254490513\n",
      "Epochs: 329 | Error: 11.182018243755733\n",
      "Epochs: 330 | Error: 11.317278103846078\n",
      "Epochs: 331 | Error: 11.430612838731399\n",
      "Epochs: 332 | Error: 10.7324208020175\n",
      "Epochs: 333 | Error: 11.203587472986532\n",
      "Epochs: 334 | Error: 11.50930406140128\n",
      "Epochs: 335 | Error: 11.31447583788626\n",
      "Epochs: 336 | Error: 11.625023102147717\n",
      "Epochs: 337 | Error: 10.889158606198336\n",
      "Epochs: 338 | Error: 10.958895066608425\n",
      "Epochs: 339 | Error: 10.925533641684481\n",
      "Epochs: 340 | Error: 11.141399270864067\n",
      "Epochs: 341 | Error: 10.85628305790556\n",
      "Epochs: 342 | Error: 11.247107990768676\n",
      "Epochs: 343 | Error: 11.436727644025195\n",
      "Epochs: 344 | Error: 10.97021830865632\n",
      "Epochs: 345 | Error: 11.282905873884356\n",
      "Epochs: 346 | Error: 11.171738164262482\n",
      "Epochs: 347 | Error: 10.93032169277894\n",
      "Epochs: 348 | Error: 11.430952502375863\n",
      "Epochs: 349 | Error: 11.083461244830316\n",
      "Epochs: 350 | Error: 11.165224939263153\n",
      "Epochs: 351 | Error: 11.203407853121771\n",
      "Epochs: 352 | Error: 11.183016627454794\n",
      "Epochs: 353 | Error: 11.47465985254895\n",
      "Epochs: 354 | Error: 11.249337328454386\n",
      "Epochs: 355 | Error: 11.329501641869125\n",
      "Epochs: 356 | Error: 11.162152748019984\n",
      "Epochs: 357 | Error: 11.105027356292265\n",
      "Epochs: 358 | Error: 11.557230497097637\n",
      "Epochs: 359 | Error: 11.188990857926182\n",
      "Epochs: 360 | Error: 11.061539081929984\n",
      "Epochs: 361 | Error: 11.32125597798018\n",
      "Epochs: 362 | Error: 11.086467284796841\n",
      "Epochs: 363 | Error: 11.31075869036704\n",
      "Epochs: 364 | Error: 11.033979405077542\n",
      "Epochs: 365 | Error: 10.612882208880297\n",
      "Epochs: 366 | Error: 10.904667636391709\n",
      "Epochs: 367 | Error: 10.992917086146912\n",
      "Epochs: 368 | Error: 11.186125708193558\n",
      "Epochs: 369 | Error: 10.866527950449639\n",
      "Epochs: 370 | Error: 11.257658326170374\n",
      "Epochs: 371 | Error: 11.276169916537192\n",
      "Epochs: 372 | Error: 11.002298381449576\n",
      "Epochs: 373 | Error: 10.860446671391095\n",
      "Epochs: 374 | Error: 11.008709026737598\n",
      "Epochs: 375 | Error: 11.029537659376595\n",
      "Epochs: 376 | Error: 11.436301195016744\n",
      "Epochs: 377 | Error: 11.118411441572917\n",
      "Epochs: 378 | Error: 11.12541093284054\n",
      "Epochs: 379 | Error: 11.006804935314639\n",
      "Epochs: 380 | Error: 11.26105879118364\n",
      "Epochs: 381 | Error: 11.139391427510791\n",
      "Epochs: 382 | Error: 10.678779056042726\n",
      "Epochs: 383 | Error: 11.447076324119918\n",
      "Epochs: 384 | Error: 10.964276554338868\n",
      "Epochs: 385 | Error: 11.297725951876743\n",
      "Epochs: 386 | Error: 11.16298062521992\n",
      "Epochs: 387 | Error: 10.826886794368079\n",
      "Epochs: 388 | Error: 11.117350129681578\n",
      "Epochs: 389 | Error: 11.325155992892798\n",
      "Epochs: 390 | Error: 11.152328860177716\n",
      "Epochs: 391 | Error: 11.080847453819986\n",
      "Epochs: 392 | Error: 10.962738969665653\n",
      "Epochs: 393 | Error: 11.024408771601175\n",
      "Epochs: 394 | Error: 10.877821483036467\n",
      "Epochs: 395 | Error: 11.173881664264774\n",
      "Epochs: 396 | Error: 11.12133722778578\n",
      "Epochs: 397 | Error: 11.236546120179018\n",
      "Epochs: 398 | Error: 11.307589790585908\n",
      "Epochs: 399 | Error: 11.437122544832992\n",
      "Epochs: 400 | Error: 11.240212750059552\n",
      "Epochs: 401 | Error: 10.872933037146618\n",
      "Epochs: 402 | Error: 11.076940824211027\n",
      "Epochs: 403 | Error: 11.261436689036628\n",
      "Epochs: 404 | Error: 10.60305511464212\n",
      "Epochs: 405 | Error: 10.887360883337003\n",
      "Epochs: 406 | Error: 11.190907432085474\n",
      "Epochs: 407 | Error: 11.064441288955177\n",
      "Epochs: 408 | Error: 11.393241443253546\n",
      "Epochs: 409 | Error: 11.242383575482133\n",
      "Epochs: 410 | Error: 11.242427566177492\n",
      "Epochs: 411 | Error: 11.263857374828564\n",
      "Epochs: 412 | Error: 11.144787074230155\n",
      "Epochs: 413 | Error: 10.7164275681395\n",
      "Epochs: 414 | Error: 11.245099619127815\n",
      "Epochs: 415 | Error: 10.965349239050525\n",
      "Epochs: 416 | Error: 11.270202727118818\n",
      "Epochs: 417 | Error: 11.178003258198563\n",
      "Epochs: 418 | Error: 11.360895987171535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 419 | Error: 11.176408304854597\n",
      "Epochs: 420 | Error: 10.79466017682979\n",
      "Epochs: 421 | Error: 10.930725580560521\n",
      "Epochs: 422 | Error: 11.450093820645883\n",
      "Epochs: 423 | Error: 10.969687573685512\n",
      "Epochs: 424 | Error: 11.344638240503896\n",
      "Epochs: 425 | Error: 10.86199951473855\n",
      "Epochs: 426 | Error: 11.011259875209527\n",
      "Epochs: 427 | Error: 10.94277329566999\n",
      "Epochs: 428 | Error: 10.973147840543206\n",
      "Epochs: 429 | Error: 11.008830599604204\n",
      "Epochs: 430 | Error: 11.259394454057537\n",
      "Epochs: 431 | Error: 10.808961004986324\n",
      "Epochs: 432 | Error: 11.160149397481796\n",
      "Epochs: 433 | Error: 11.264527960459823\n",
      "Epochs: 434 | Error: 11.474053566215801\n",
      "Epochs: 435 | Error: 10.616224815642557\n",
      "Epochs: 436 | Error: 10.789179878075982\n",
      "Epochs: 437 | Error: 11.145371214343097\n",
      "Epochs: 438 | Error: 10.845747172149757\n",
      "Epochs: 439 | Error: 11.143132950862075\n",
      "Epochs: 440 | Error: 11.011466051413098\n",
      "Epochs: 441 | Error: 11.071225407714039\n",
      "Epochs: 442 | Error: 11.202021037315212\n",
      "Epochs: 443 | Error: 11.14962754842406\n",
      "Epochs: 444 | Error: 11.077225275229742\n",
      "Epochs: 445 | Error: 11.276094700321245\n",
      "Epochs: 446 | Error: 11.114877132132124\n",
      "Epochs: 447 | Error: 10.92739040254749\n",
      "Epochs: 448 | Error: 10.99289841488894\n",
      "Epochs: 449 | Error: 11.131665269521497\n",
      "Epochs: 450 | Error: 10.93581947465605\n",
      "Epochs: 451 | Error: 11.107447476429304\n",
      "Epochs: 452 | Error: 11.034264302114533\n",
      "Epochs: 453 | Error: 11.36083470789856\n",
      "Epochs: 454 | Error: 10.747419090654141\n",
      "Epochs: 455 | Error: 11.32046818566814\n",
      "Epochs: 456 | Error: 10.927293969326543\n",
      "Epochs: 457 | Error: 11.042967616342745\n",
      "Epochs: 458 | Error: 10.735843546984205\n",
      "Epochs: 459 | Error: 10.794180110409506\n",
      "Epochs: 460 | Error: 10.963309202805915\n",
      "Epochs: 461 | Error: 10.956557796949495\n",
      "Epochs: 462 | Error: 11.083490374485821\n",
      "Epochs: 463 | Error: 11.199993490530911\n",
      "Epochs: 464 | Error: 10.657912619613555\n",
      "Epochs: 465 | Error: 10.71878810067242\n",
      "Epochs: 466 | Error: 11.063752539070995\n",
      "Epochs: 467 | Error: 11.356521685501939\n",
      "Epochs: 468 | Error: 10.923646623749937\n",
      "Epochs: 469 | Error: 11.296076919479662\n",
      "Epochs: 470 | Error: 10.955843765403085\n",
      "Epochs: 471 | Error: 11.264363775759113\n",
      "Epochs: 472 | Error: 11.076498834197777\n",
      "Epochs: 473 | Error: 10.961933307970844\n",
      "Epochs: 474 | Error: 11.064386592949448\n",
      "Epochs: 475 | Error: 11.186229635232355\n",
      "Epochs: 476 | Error: 10.87119027569502\n",
      "Epochs: 477 | Error: 10.820488853866893\n",
      "Epochs: 478 | Error: 10.908157733143046\n",
      "Epochs: 479 | Error: 11.309809654682573\n",
      "Epochs: 480 | Error: 11.102600760937623\n",
      "Epochs: 481 | Error: 11.54926460216407\n",
      "Epochs: 482 | Error: 11.373735662368489\n",
      "Epochs: 483 | Error: 11.185962469231153\n",
      "Epochs: 484 | Error: 11.425256891483242\n",
      "Epochs: 485 | Error: 11.28623701812539\n",
      "Epochs: 486 | Error: 10.806865147760702\n",
      "Epochs: 487 | Error: 11.55773459674368\n",
      "Epochs: 488 | Error: 11.353907983346126\n",
      "Epochs: 489 | Error: 11.05756490109069\n",
      "Epochs: 490 | Error: 10.473657786071252\n",
      "Epochs: 491 | Error: 11.1026418276814\n",
      "Epochs: 492 | Error: 10.981286763477524\n",
      "Epochs: 493 | Error: 11.174590078066881\n",
      "Epochs: 494 | Error: 11.116767774426913\n",
      "Epochs: 495 | Error: 11.108242210340867\n",
      "Epochs: 496 | Error: 10.914270472581663\n",
      "Epochs: 497 | Error: 10.612231257761481\n",
      "Epochs: 498 | Error: 11.309888685486602\n",
      "Epochs: 499 | Error: 10.884440595284712\n",
      "Epochs: 500 | Error: 11.262672535776519\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 501):\n",
    "    reset_params()\n",
    "    train_network(0.001953125, epochs=i)\n",
    "    print(f'Epochs: {i} | Error: {performance()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bd1f488c-f7ce-4248-9ad2-cc572723d087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test performance on an extremely complexe network structure\n",
    "# Network parameters\n",
    "R = 4\n",
    "layer_sizes = [4, 1024, 1024, 1024, 1024]\n",
    "transfer_functions = [logsig, logsig, logsig, logsig, lin]\n",
    "deriv_transfer_functions = [deriv_logsig, deriv_logsig, deriv_logsig, deriv_logsig, deriv_lin]\n",
    "# Inputs and outputs\n",
    "inputs, outputs, S = gen_inputs_outputs(R)\n",
    "layer_sizes = np.array(layer_sizes + [S], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "92dfc2b5-c9df-4bf2-bcd8-e6cda2fdd5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2955718257616284e+190\n"
     ]
    }
   ],
   "source": [
    "reset_params()\n",
    "train_network(0.001953125, epochs=12)\n",
    "print(performance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5649a34f-a7ad-463a-9402-b72e5a9e3c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18f00e57-ffe2-4019-befa-371b308d4aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(layer_sizes[1], input_shape=(layer_sizes[0],), activation='sigmoid'))\n",
    "model.add(Dense(layer_sizes[2], activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1461c9e-d5ff-46f6-bf5d-d3d912900cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.5000 - loss: 7.0425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1672a4dd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdg = SGD(.9)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=sdg,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "model.fit(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94cda203-692a-464f-a3e4-0ef7c23a265e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.01186371, -8.282264  , -1.4656483 ],\n",
       "       [ 0.0887537 , -9.469966  , -1.5549538 ],\n",
       "       [ 0.15937938, -8.323184  , -1.3819622 ],\n",
       "       [ 0.22767666, -9.4916    , -1.4718292 ],\n",
       "       [-0.01628557, -8.611647  , -1.6199257 ],\n",
       "       [ 0.04203045, -9.72632   , -1.6907108 ],\n",
       "       [ 0.14307892, -8.662352  , -1.5352875 ],\n",
       "       [ 0.20412186, -9.765932  , -1.603532  ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow25",
   "language": "python",
   "name": "tensorflow25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
