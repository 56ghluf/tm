{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b84f3c0d-0ef4-4786-a173-f84ae624f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f472b88-a3a4-4b8d-a53e-18e34ff70219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tools\n",
    "from sys import path\n",
    "path.append('/Users/reid/dev/PythonCode/tm/tools')\n",
    "path.append('D:/PythonCode/tm/tools')\n",
    "from tools import gen_inputs_outputs, logsig, lin, deriv_logsig, deriv_lin, e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bfddd31-1531-4b5f-9b6e-26726405aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of the network\n",
    "# Order by layers (input, layer1, layer2, ...)\n",
    "# !!! No output layer yet, wait to gen inputs\n",
    "layer_sizes = [4, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79899160-bb87-42b0-9724-442688c4fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gen inputs, outputs and size of the last layer\n",
    "inputs, outputs, S = gen_inputs_outputs(layer_sizes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbf53b7f-a7bc-44b9-82df-d9f112726b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the output layer size\n",
    "layer_sizes = np.array(layer_sizes + [S], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c1a6b04-33fd-4159-80c3-4590112d951b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 7, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Network shape\n",
    "layer_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b93dbe42-c6ff-40d8-963b-d38d7c9c6381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 1],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 1],\n",
       "       [0, 1, 1, 0],\n",
       "       [0, 1, 1, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 1],\n",
       "       [1, 0, 1, 0],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 1, 0, 0],\n",
       "       [1, 1, 0, 1],\n",
       "       [1, 1, 1, 0],\n",
       "       [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inputs\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae97cbdf-c716-48e4-ae91-3d6fab5fbc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outputs\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df41116d-c038-4df0-a8b7-bbd6672d9192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize the weights and biases randomly\n",
    "# Also create the list to store the outputs of each layer\n",
    "# Store the outptut for each layer\n",
    "# Finally create the list of the sensitivities\n",
    "weights_list = []\n",
    "biases_list = []\n",
    "n_list = []\n",
    "a_list = []\n",
    "s_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff640418-72ed-4f90-b9eb-833bc8e09cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to reset all the parameters\n",
    "# This is done to test multiple different network types\n",
    "def reset_params():\n",
    "    weights_list.clear()\n",
    "    biases_list.clear()\n",
    "    n_list.clear()\n",
    "    a_list.clear()\n",
    "    s_list.clear()\n",
    "    for i in range(1, len(layer_sizes)):\n",
    "        weights_list.append(np.random.rand(layer_sizes[i], layer_sizes[i-1]))\n",
    "        biases_list.append(np.random.rand(layer_sizes[i], 1))\n",
    "        n_list.append(np.empty((layer_sizes[i], 1), dtype=float))\n",
    "        a_list.append(np.empty((layer_sizes[i], 1), dtype=float))\n",
    "        s_list.append(np.empty((layer_sizes[i], 1), dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "040cdd31-cac6-4a10-9c96-2948d962c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transfer functions\n",
    "transfer_functions = [logsig, lin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f34b2228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vectors with the derivatives of the transfer functions\n",
    "# These need to be converted to dialation matrices\n",
    "# but this is done after the partial derivatives are calculated\n",
    "# so that the numerical values can be multiplied by the identity matrix\n",
    "# makes my life easier\n",
    "deriv_transfer_functions = [deriv_logsig, deriv_lin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "727d6d3b-bb81-41b1-a20e-79d86f88da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the output of the network\n",
    "# while also saving the data\n",
    "# Assuming that the input is already a Rx1 matrix\n",
    "def run_network(X):\n",
    "    # Get the input for the first layer so that\n",
    "    # no need to use X and can calculate\n",
    "    # recursively\n",
    "    n_list[0] = np.matmul(weights_list[0], X) + biases_list[0]\n",
    "    a_list[0] = transfer_functions[0](n_list[0])\n",
    "\n",
    "    # Calculate the rest of the outptut\n",
    "    for i in range(1, len(weights_list)):\n",
    "        n_list[i] = np.matmul(weights_list[i], a_list[i-1]) + biases_list[i]\n",
    "        a_list[i] = transfer_functions[i](n_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "430cdf1f-3c41-4f7b-8f10-7fe740c3fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the senstivites for the last layer\n",
    "# Write a function to fill the diagonal of the matrix\n",
    "def fill_F_dot(layer_num):\n",
    "    a = np.identity(len(n_list[layer_num]), float)\n",
    "    np.fill_diagonal(a, deriv_transfer_functions[layer_num](n_list[layer_num]).flatten())\n",
    "    return a\n",
    "\n",
    "def train_network(learning_rate=.1, epochs=1):\n",
    "    for i in range(epochs):\n",
    "        # Iterate through the inputs and outputs\n",
    "        for i in range(len(inputs)):\n",
    "            # Run the network\n",
    "            run_network(inputs[i].reshape(layer_sizes[0], 1))\n",
    "\n",
    "            # Get the dialation matrix for the last layer\n",
    "            F_dot = fill_F_dot(-1)\n",
    "\n",
    "            # Calculate the sensitivites for the last layer\n",
    "            s_list[-1] = -2 * np.matmul(F_dot, outputs[i].reshape(layer_sizes[-1], 1)-a_list[-1])\n",
    "\n",
    "            # Update the weights and biases for the last layer\n",
    "            weights_list[-1] += -learning_rate*np.matmul(s_list[-1], a_list[-2].T)\n",
    "            biases_list[-1] += -learning_rate*s_list[-1]\n",
    "\n",
    "            # Iterate through the remaining layers backwards\n",
    "            for i in range(len(n_list)-2, 0, -1):\n",
    "                s_list[i] = np.matmul(np.matmul(fill_F_dot(i), weights_list[i+1].T), s_list[i+1])\n",
    "                weights_list[i] += -learning_rate*np.matmul(s_list[i], a_list[i-1].T)\n",
    "                biases_list[i] += -learning_rate*s_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2795ae9-2a81-4d6d-8985-3d59af9425e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to evaluate the performance\n",
    "# of the network\n",
    "def performance():\n",
    "    results = np.empty((len(inputs), layer_sizes[-1]), dtype=float)\n",
    "    for i in range(len(inputs)):\n",
    "        run_network(inputs[i].reshape(layer_sizes[0], 1))\n",
    "        results[i] = outputs[i] - a_list[-1].flatten()\n",
    "    return e2(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e825b533-0f93-4b76-8195-415d5b3b9065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print performance\n",
    "def print_performance_dict(performance_dict):\n",
    "    for a in sorted(performance_dict.items(), key=lambda x: x[1]):\n",
    "        print(f'Error: {a[1]}' + a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac7602d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains netowrk using the parameters for each bit size\n",
    "def update_performance_dict(layer_sizes_list, performance_dict):\n",
    "    for layer_sizes in layer_sizes_list:\n",
    "        # Get the inputs and outputs for the specifiq network size\n",
    "        inputs, outputs, S = gen_inputs_outputs(layer_sizes[0])\n",
    "        layer_sizes.append(S)\n",
    "    \n",
    "        # Iterate through the different learning rates\n",
    "        # and epochs\n",
    "        for rate in learning_rates:\n",
    "            for epochs in epochs_list:\n",
    "                # Reset weights and biases\n",
    "                reset_params()\n",
    "                # Train the network\n",
    "                train_network(learning_rate=rate, epochs=epochs)\n",
    "                # Update the performance dict\n",
    "                performance_dict.update({f'Layers: {layer_sizes}, Learning rate: {rate}, Epochs: {epochs}': performance()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60afa525-7577-458f-b6e3-8a4cf362b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "### !!! Do not run code underneath until saving to the file\n",
    "### It trains 24000 different networks\n",
    "# Performance dictionnaries of the network\n",
    "performance_dict_2bits = {}\n",
    "performance_dict_4bits = {}\n",
    "performance_dict_8bits = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "957eb418-c39e-4a66-9023-4af7573462b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters that won't change despite differnt layer sizes\n",
    "# Set different learning rates\n",
    "learning_rates = [1/(16*(2**i)) for i in range(10)]\n",
    "\n",
    "# Set the diffrent epochs\n",
    "epochs_list = [i for i in range(1, 21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48a0e709",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Multiple different layer sizes\n",
    "# Start with 1 hidden layer\n",
    "layer_sizes_list_2bits = [[4, 2*(2**i)]for i in range(10)]\n",
    "layer_sizes_list_4bits = [[8, 2*(2**i)]for i in range(10)]\n",
    "layer_sizes_list_8bits = [[16, 2*(2**i)]for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d0f0575-efb5-4c96-85df-fc0e1450e68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance for 1 hidden layer\n",
    "# 2 bits\n",
    "update_performance_dict(layer_sizes_list_2bits, performance_dict_2bits)\n",
    "# 4 bits\n",
    "update_performance_dict(layer_sizes_list_4bits, performance_dict_4bits)\n",
    "# 8 bits\n",
    "update_performance_dict(layer_sizes_list_8bits, performance_dict_8bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c10735f5-04b3-4432-8436-af626574fe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Hidden layers\n",
    "# Redefine the transfer functions\n",
    "transfer_funtions = [logsig, logsig, lin]\n",
    "deriv_transfer_functions = [deriv_logsig, deriv_logsig, deriv_lin]\n",
    "\n",
    "# New layer sizes\n",
    "layer_sizes_list_2bits = [[4, 2*(2**i), 2*(2**j)] for j in range(10) for i in range(10)]\n",
    "layer_sizes_list_4bits = [[8, 2*(2**i), 2*(2**j)] for j in range(10) for i in range(10)]\n",
    "layer_sizes_list_8bits = [[16, 2*(2**i), 2*(2**j)] for j in range(10) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f90dadf-2fc3-49be-a7c8-4248f4b59ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the performance for 2 hidden layers\n",
    "# 2 bits\n",
    "update_performance_dict(layer_sizes_list_2bits, performance_dict_2bits)\n",
    "# 4 bits\n",
    "update_performance_dict(layer_sizes_list_4bits, performance_dict_4bits)\n",
    "# 8 bits\n",
    "update_performance_dict(layer_sizes_list_8bits, performance_dict_8bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7df991ea-5884-49ee-b418-1e9edd3e688c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('-'*7 + '2bits' + '-'*7)\n",
    "print_performance_dict(performance_dict_2bits)\n",
    "print('-'*7 + '4bits' + '-'*7)\n",
    "print_performance_dict(performance_dict_4bits)\n",
    "print('-'*7 + '8bits' + '-'*7)\n",
    "print_performance_dict(performance_dict_8bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb685cf8-803e-450a-a063-e21cdd3fc840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data of the performance dicts\n",
    "performance_dicts = [performance_dict_2bits, performance_dict_4bits, performance_dict_8bits]\n",
    "for i in range(len(performance_dicts)):\n",
    "    with open(f'/Users/reid/dev/PythonCode/tm/BackPropagationBinaryCalcs/data/{2**(i+1)}bit_performance.txt', 'w') as f:\n",
    "        f.write('parameters,performance\\n')\n",
    "        f.writelines([f'{x}\\n' for x in sorted(list(performance_dicts[i].items()), key=lambda x: x[1], reverse=True)])\n",
    "### You can run code below this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5649a34f-a7ad-463a-9402-b72e5a9e3c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18f00e57-ffe2-4019-befa-371b308d4aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(layer_sizes[1], input_shape=(layer_sizes[0],), activation='sigmoid'))\n",
    "model.add(Dense(layer_sizes[2], activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1461c9e-d5ff-46f6-bf5d-d3d912900cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.5000 - loss: 7.0425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1672a4dd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdg = SGD(.9)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=sdg,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "model.fit(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94cda203-692a-464f-a3e4-0ef7c23a265e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.01186371, -8.282264  , -1.4656483 ],\n",
       "       [ 0.0887537 , -9.469966  , -1.5549538 ],\n",
       "       [ 0.15937938, -8.323184  , -1.3819622 ],\n",
       "       [ 0.22767666, -9.4916    , -1.4718292 ],\n",
       "       [-0.01628557, -8.611647  , -1.6199257 ],\n",
       "       [ 0.04203045, -9.72632   , -1.6907108 ],\n",
       "       [ 0.14307892, -8.662352  , -1.5352875 ],\n",
       "       [ 0.20412186, -9.765932  , -1.603532  ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tm",
   "language": "python",
   "name": "tm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
