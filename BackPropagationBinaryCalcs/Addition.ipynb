{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b84f3c0d-0ef4-4786-a173-f84ae624f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f472b88-a3a4-4b8d-a53e-18e34ff70219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tools\n",
    "from sys import path\n",
    "path.append('/Users/reid/dev/PythonCode/tm/tools')\n",
    "path.append('D:/PythonCode/tm/tools')\n",
    "from tools import gen_inputs_outputs, logsig, lin, deriv_logsig, deriv_lin, e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bfddd31-1531-4b5f-9b6e-26726405aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of the network\n",
    "# Order by layers (input, layer1, layer2, ...)\n",
    "# !!! No output layer yet, wait to gen inputs\n",
    "layer_sizes = [4, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79899160-bb87-42b0-9724-442688c4fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gen inputs, outputs and size of the last layer\n",
    "inputs, outputs, S = gen_inputs_outputs(layer_sizes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbf53b7f-a7bc-44b9-82df-d9f112726b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the output layer size\n",
    "layer_sizes = np.array(layer_sizes + [S], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c1a6b04-33fd-4159-80c3-4590112d951b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 7, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Network shape\n",
    "layer_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b93dbe42-c6ff-40d8-963b-d38d7c9c6381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 1],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 1],\n",
       "       [0, 1, 1, 0],\n",
       "       [0, 1, 1, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 1],\n",
       "       [1, 0, 1, 0],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 1, 0, 0],\n",
       "       [1, 1, 0, 1],\n",
       "       [1, 1, 1, 0],\n",
       "       [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inputs\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae97cbdf-c716-48e4-ae91-3d6fab5fbc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outputs\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df41116d-c038-4df0-a8b7-bbd6672d9192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize the weights and biases randomly\n",
    "# Also create the list to store the outputs of each layer\n",
    "# Store the outptut for each layer\n",
    "# Finally create the list of the sensitivities\n",
    "weights_list = []\n",
    "biases_list = []\n",
    "n_list = []\n",
    "a_list = []\n",
    "s_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff640418-72ed-4f90-b9eb-833bc8e09cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to reset all the parameters\n",
    "# This is done to test multiple different network types\n",
    "def reset_params():\n",
    "    weights_list.clear()\n",
    "    biases_list.clear()\n",
    "    n_list.clear()\n",
    "    a_list.clear()\n",
    "    s_list.clear()\n",
    "    for i in range(1, len(layer_sizes)):\n",
    "        weights_list.append(np.random.rand(layer_sizes[i], layer_sizes[i-1]))\n",
    "        biases_list.append(np.random.rand(layer_sizes[i], 1))\n",
    "        n_list.append(np.empty((layer_sizes[i], 1), dtype=float))\n",
    "        a_list.append(np.empty((layer_sizes[i], 1), dtype=float))\n",
    "        s_list.append(np.empty((layer_sizes[i], 1), dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "040cdd31-cac6-4a10-9c96-2948d962c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transfer functions\n",
    "transfer_functions = [logsig, lin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f34b2228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vectors with the derivatives of the transfer functions\n",
    "# These need to be converted to dialation matrices\n",
    "# but this is done after the partial derivatives are calculated\n",
    "# so that the numerical values can be multiplied by the identity matrix\n",
    "# makes my life easier\n",
    "deriv_transfer_functions = [deriv_logsig, deriv_lin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "727d6d3b-bb81-41b1-a20e-79d86f88da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the output of the network\n",
    "# while also saving the data\n",
    "# Assuming that the input is already a Rx1 matrix\n",
    "def run_network(X):\n",
    "    # Get the input for the first layer so that\n",
    "    # no need to use X and can calculate\n",
    "    # recursively\n",
    "    n_list[0] = np.matmul(weights_list[0], X) + biases_list[0]\n",
    "    a_list[0] = transfer_functions[0](n_list[0])\n",
    "\n",
    "    # Calculate the rest of the outptut\n",
    "    for i in range(1, len(weights_list)):\n",
    "        n_list[i] = np.matmul(weights_list[i], a_list[i-1]) + biases_list[i]\n",
    "        a_list[i] = transfer_functions[i](n_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "430cdf1f-3c41-4f7b-8f10-7fe740c3fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the senstivites for the last layer\n",
    "# Write a function to fill the diagonal of the matrix\n",
    "def fill_F_dot(layer_num):\n",
    "    a = np.identity(len(n_list[layer_num]), float)\n",
    "    np.fill_diagonal(a, deriv_transfer_functions[layer_num](n_list[layer_num]).flatten())\n",
    "    return a\n",
    "\n",
    "def train_network(learning_rate=.1, epochs=1):\n",
    "    for i in range(epochs):\n",
    "        # Iterate through the inputs and outputs\n",
    "        for i in range(len(inputs)):\n",
    "            # Run the network\n",
    "            run_network(inputs[i].reshape(layer_sizes[0], 1))\n",
    "\n",
    "            # Get the dialation matrix for the last layer\n",
    "            F_dot = fill_F_dot(-1)\n",
    "\n",
    "            # Calculate the sensitivites for the last layer\n",
    "            s_list[-1] = -2 * np.matmul(F_dot, outputs[i].reshape(layer_sizes[-1], 1)-a_list[-1])\n",
    "\n",
    "            # Update the weights and biases for the last layer\n",
    "            weights_list[-1] += -learning_rate*np.matmul(s_list[-1], a_list[-2].T)\n",
    "            biases_list[-1] += -learning_rate*s_list[-1]\n",
    "\n",
    "            # Iterate through the remaining layers backwards\n",
    "            for i in range(len(n_list)-2, 0, -1):\n",
    "                s_list[i] = (1/layer_sizes[i+1]) * np.matmul(np.matmul(fill_F_dot(i), weights_list[i+1].T), s_list[i+1])\n",
    "                weights_list[i] += -learning_rate*np.matmul(s_list[i], a_list[i-1].T)\n",
    "                biases_list[i] += -learning_rate*s_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2795ae9-2a81-4d6d-8985-3d59af9425e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to evaluate the performance\n",
    "# of the network\n",
    "def performance():\n",
    "    results = np.empty((len(inputs), layer_sizes[-1]), dtype=float)\n",
    "    for i in range(len(inputs)):\n",
    "        run_network(inputs[i].reshape(layer_sizes[0], 1))\n",
    "        results[i] = outputs[i] - a_list[-1].flatten()\n",
    "    return e2(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e825b533-0f93-4b76-8195-415d5b3b9065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print performance\n",
    "def print_performance_dict(performance_dict):\n",
    "    for a in sorted(performance_dict.items(), key=lambda x: x[1]):\n",
    "        print(f'Error: {a[1]} | ' + a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac7602d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains netowrk using the parameters for each bit size\n",
    "def update_performance_dict(layer_sizes_list, performance_dict):\n",
    "    for layer_sizes in layer_sizes_list:\n",
    "        # Get the inputs and outputs for the specifiq network size\n",
    "        inputs, outputs, S = gen_inputs_outputs(layer_sizes[0])\n",
    "        layer_sizes.append(S)\n",
    "    \n",
    "        # Iterate through the different learning rates\n",
    "        # and epochs\n",
    "        for rate in learning_rates:\n",
    "            for epochs in epochs_list:\n",
    "                # Reset weights and biases\n",
    "                reset_params()\n",
    "                # Train the network\n",
    "                train_network(learning_rate=rate, epochs=epochs)\n",
    "                # Update the performance dict\n",
    "                performance_dict.update({f'Layers: {layer_sizes}, Learning rate: {rate}, Epochs: {epochs}': performance()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60afa525-7577-458f-b6e3-8a4cf362b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "### !!! Do not run code underneath until saving to the file\n",
    "### It trains 22000 different networks\n",
    "# Performance dictionnaries of the network\n",
    "performance_dict_2bits = {}\n",
    "performance_dict_4bits = {}\n",
    "performance_dict_8bits = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "957eb418-c39e-4a66-9023-4af7573462b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters that won't change despite differnt layer sizes\n",
    "# Set different learning rates\n",
    "learning_rates = [1/(16*(2**i)) for i in range(10)]\n",
    "\n",
    "# Set the diffrent epochs\n",
    "epochs_list = [i for i in range(1, 21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48a0e709",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Multiple different layer sizes\n",
    "# Start with 1 hidden layer\n",
    "layer_sizes_list_2bits = [[4, 2*(2**i)]for i in range(10)]\n",
    "layer_sizes_list_4bits = [[8, 2*(2**i)]for i in range(10)]\n",
    "layer_sizes_list_8bits = [[16, 2*(2**i)]for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d0f0575-efb5-4c96-85df-fc0e1450e68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance for 1 hidden layer\n",
    "# 2 bits\n",
    "update_performance_dict(layer_sizes_list_2bits, performance_dict_2bits)\n",
    "# 4 bits\n",
    "update_performance_dict(layer_sizes_list_4bits, performance_dict_4bits)\n",
    "# 8 bits\n",
    "update_performance_dict(layer_sizes_list_8bits, performance_dict_8bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c10735f5-04b3-4432-8436-af626574fe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Hidden layers\n",
    "# Redefine the transfer functions\n",
    "transfer_functions = [logsig, logsig, lin]\n",
    "deriv_transfer_functions = [deriv_logsig, deriv_logsig, deriv_lin]\n",
    "\n",
    "# New layer sizes\n",
    "layer_sizes_list_2bits = [[4, 2*(2**i), 2*(2**j)] for j in range(10) for i in range(10)]\n",
    "layer_sizes_list_4bits = [[8, 2*(2**i), 2*(2**j)] for j in range(10) for i in range(10)]\n",
    "layer_sizes_list_8bits = [[16, 2*(2**i), 2*(2**j)] for j in range(10) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f90dadf-2fc3-49be-a7c8-4248f4b59ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the performance for 2 hidden layers\n",
    "# 2 bits\n",
    "update_performance_dict(layer_sizes_list_2bits, performance_dict_2bits)\n",
    "# 4 bits\n",
    "update_performance_dict(layer_sizes_list_4bits, performance_dict_4bits)\n",
    "# 8 bits\n",
    "update_performance_dict(layer_sizes_list_8bits, performance_dict_8bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7df991ea-5884-49ee-b418-1e9edd3e688c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('-'*7 + '2bits' + '-'*7)\n",
    "print_performance_dict(performance_dict_2bits)\n",
    "print('-'*7 + '4bits' + '-'*7)\n",
    "print_performance_dict(performance_dict_4bits)\n",
    "print('-'*7 + '8bits' + '-'*7)\n",
    "print_performance_dict(performance_dict_8bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb685cf8-803e-450a-a063-e21cdd3fc840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data of the performance dicts\n",
    "performance_dicts = [performance_dict_2bits, performance_dict_4bits, performance_dict_8bits]\n",
    "for i in range(len(performance_dicts)):\n",
    "    with open(f'/Users/reid/dev/PythonCode/tm/BackPropagationBinaryCalcs/data/{2**(i+1)}bit_performance.txt', 'w') as f:\n",
    "        f.write('parameters,performance\\n')\n",
    "        f.writelines([f'{x}\\n' for x in sorted(list(performance_dicts[i].items()), key=lambda x: x[1], reverse=True)])\n",
    "### You can run code below this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2379fd6e-0469-46dc-9b68-d910b7c469bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chose a few networks from the data file to run tests on\n",
    "# General parameters\n",
    "learning_rates = [0.001953125, 0.00390625, 0.0078125]\n",
    "epochs_list = [12, 15, 17, 5, 14, 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3934c577-4e55-4162-b10e-39b5740597da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with one hidden layer\n",
    "transfer_functions = [logsig, lin]\n",
    "deriv_transfer_functions = [deriv_logsig, deriv_lin]\n",
    "\n",
    "layer_sizes_list_2bits = [\n",
    "    [4, 2],\n",
    "    [4, 32],\n",
    "    [4, 64],\n",
    "]\n",
    "layer_sizes_list_4bits = [\n",
    "    [8, 64],\n",
    "    [8, 2],\n",
    "    [8, 1024],\n",
    "]\n",
    "layer_sizes_list_8bits = [\n",
    "    [16, 16],\n",
    "    [16, 64],\n",
    "    [16, 4],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9e87e10-d95d-42b8-8073-6e2e0cee87e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to calculate the average performance\n",
    "def update_average_performance_dict(layer_sizes_list, average_performance_dict, n_samples):\n",
    "    for layer_sizes in layer_sizes_list:\n",
    "        inputs, outputs, S = gen_inputs_outputs(layer_sizes[0])\n",
    "        layer_sizes.append(S)\n",
    "\n",
    "        cumulated_performance = 0\n",
    "        \n",
    "        for rate in learning_rates:\n",
    "                for epochs in epochs_list:\n",
    "                    for i in range(n_samples):\n",
    "                        reset_params()\n",
    "                        train_network(learning_rate=rate, epochs=epochs)\n",
    "                        cumulated_performance += performance()\n",
    "                        \n",
    "                    average_performance_dict.update({f'Layers: {layer_sizes}, Learning rate: {rate}, Epochs: {epochs}': cumulated_performance/n_samples})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc88c856-fd54-430b-8889-fec8af69db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_performance_dict_2bits = {}\n",
    "average_performance_dict_4bits = {}\n",
    "average_performance_dict_8bits = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8df65e5-bae1-47e5-814a-0cc1d73b5511",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_average_performance_dict(layer_sizes_list_2bits, average_performance_dict_2bits, 500)\n",
    "update_average_performance_dict(layer_sizes_list_4bits, average_performance_dict_4bits, 500)\n",
    "update_average_performance_dict(layer_sizes_list_8bits, average_performance_dict_8bits, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69fdb65c-6136-442b-8ccd-0f45f7daa461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two hidden layers\n",
    "transfer_functions = [logsig, logsig, lin]\n",
    "deriv_transfer_functions = [deriv_logsig, deriv_logsig, deriv_lin]\n",
    "\n",
    "layer_sizes_list_2bits = [\n",
    "    [4, 8, 2],\n",
    "    [4, 2, 128],\n",
    "    [4, 256, 32],\n",
    "]\n",
    "layer_sizes_list_4bits = [\n",
    "    [8, 32, 64],\n",
    "    [8, 1024, 64],\n",
    "    [8, 2, 256],\n",
    "]\n",
    "layer_sizes_list_8bits = [\n",
    "    [16, 8, 8],\n",
    "    [16, 2, 1024],\n",
    "    [16, 16, 4],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8214975-888b-47c6-a8b1-023ff536c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_average_performance_dict(layer_sizes_list_2bits, average_performance_dict_2bits, 500)\n",
    "update_average_performance_dict(layer_sizes_list_4bits, average_performance_dict_4bits, 500)\n",
    "update_average_performance_dict(layer_sizes_list_8bits, average_performance_dict_8bits, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4f42f99-ecc1-4622-bbac-6ef2ae645b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------2 bit average----------\n",
      "Error: 11.479299935406559 | Layers: [4, 2, 3], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 11.53308861576714 | Layers: [4, 64, 3], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 11.542363713634707 | Layers: [4, 32, 3], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 17.803159669594926 | Layers: [4, 256, 32, 3], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 17.81829355607529 | Layers: [4, 8, 2, 3], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 17.8565476440209 | Layers: [4, 2, 128, 3], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 22.912720139622905 | Layers: [4, 2, 3], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 22.932651544335705 | Layers: [4, 32, 3], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 22.959130223979894 | Layers: [4, 64, 3], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 34.038750350235546 | Layers: [4, 256, 32, 3], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 34.04837897686988 | Layers: [4, 8, 2, 3], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 34.11924538239579 | Layers: [4, 2, 128, 3], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 34.28332421740538 | Layers: [4, 2, 3], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 34.31304517781144 | Layers: [4, 32, 3], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 34.35375151780721 | Layers: [4, 64, 3], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 49.36942675626122 | Layers: [4, 256, 32, 3], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 49.38338423215539 | Layers: [4, 8, 2, 3], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 49.52280423092537 | Layers: [4, 2, 128, 3], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 58.60442767862088 | Layers: [4, 2, 3], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 58.66639067788805 | Layers: [4, 32, 3], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 58.933351599465986 | Layers: [4, 64, 3], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 70.0275682740699 | Layers: [4, 2, 3], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 70.089178783494 | Layers: [4, 32, 3], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 70.38063486676334 | Layers: [4, 64, 3], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 70.98568308373444 | Layers: [4, 256, 32, 3], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 70.99059953993759 | Layers: [4, 8, 2, 3], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 71.14545888182603 | Layers: [4, 2, 128, 3], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 81.39286545906315 | Layers: [4, 2, 3], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 81.47058875756592 | Layers: [4, 32, 3], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 81.76174797041534 | Layers: [4, 64, 3], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 87.76474027182607 | Layers: [4, 8, 2, 3], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 87.77751840108593 | Layers: [4, 256, 32, 3], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 87.8332995522739 | Layers: [4, 2, 128, 3], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 92.79722139419324 | Layers: [4, 2, 3], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 92.89517344214096 | Layers: [4, 32, 3], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 93.18855003677086 | Layers: [4, 64, 3], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 102.282125241387 | Layers: [4, 256, 32, 3], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 102.32003885677472 | Layers: [4, 8, 2, 3], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 102.39766605362973 | Layers: [4, 2, 128, 3], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 104.20002494696524 | Layers: [4, 2, 3], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 104.32266576587459 | Layers: [4, 32, 3], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 104.58721422613664 | Layers: [4, 64, 3], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 115.46415607919238 | Layers: [4, 256, 32, 3], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 115.50099414504072 | Layers: [4, 8, 2, 3], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 115.55574033935808 | Layers: [4, 2, 128, 3], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 115.60413676218269 | Layers: [4, 2, 3], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 115.70691812415889 | Layers: [4, 32, 3], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 115.99897084846954 | Layers: [4, 64, 3], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 127.5493452660428 | Layers: [4, 2, 3], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 127.64881278518982 | Layers: [4, 32, 3], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 127.81120370609823 | Layers: [4, 256, 32, 3], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 127.84318478986899 | Layers: [4, 8, 2, 3], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 127.90506834685497 | Layers: [4, 2, 128, 3], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 127.94775853931539 | Layers: [4, 64, 3], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 138.96037980835303 | Layers: [4, 2, 3], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 139.06233686133976 | Layers: [4, 32, 3], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 139.3655311354261 | Layers: [4, 64, 3], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 139.89600284771336 | Layers: [4, 256, 32, 3], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 139.9271685143888 | Layers: [4, 8, 2, 3], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 139.99754040526437 | Layers: [4, 2, 128, 3], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 150.3503629924623 | Layers: [4, 2, 3], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 150.464779124257 | Layers: [4, 32, 3], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 150.77549497196236 | Layers: [4, 64, 3], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 158.8047501555472 | Layers: [4, 256, 32, 3], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 158.9052246893548 | Layers: [4, 8, 2, 3], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 158.96001959048374 | Layers: [4, 2, 128, 3], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 161.94966983426502 | Layers: [4, 2, 3], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 162.0416430199122 | Layers: [4, 32, 3], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 162.35469431245951 | Layers: [4, 64, 3], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 171.35647901250198 | Layers: [4, 256, 32, 3], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 171.44777136646732 | Layers: [4, 8, 2, 3], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 171.49304809809826 | Layers: [4, 2, 128, 3], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 173.51408040157574 | Layers: [4, 2, 3], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 173.578183403458 | Layers: [4, 32, 3], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 173.91250825668513 | Layers: [4, 64, 3], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 183.30553497292775 | Layers: [4, 256, 32, 3], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 183.3976909174778 | Layers: [4, 8, 2, 3], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 183.43931897480365 | Layers: [4, 2, 128, 3], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 185.0585143209214 | Layers: [4, 2, 3], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 185.09990408752645 | Layers: [4, 32, 3], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 185.42613607161735 | Layers: [4, 64, 3], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 195.1549796568752 | Layers: [4, 256, 32, 3], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 195.24287826939462 | Layers: [4, 8, 2, 3], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 195.29777870463082 | Layers: [4, 2, 128, 3], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 196.710943225851 | Layers: [4, 2, 3], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 196.75924577022224 | Layers: [4, 32, 3], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 197.08214169115206 | Layers: [4, 64, 3], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 206.96112834115237 | Layers: [4, 256, 32, 3], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 207.05459673490415 | Layers: [4, 8, 2, 3], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 207.1076393886222 | Layers: [4, 2, 128, 3], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 208.27056520035603 | Layers: [4, 2, 3], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 208.34494129472404 | Layers: [4, 32, 3], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 208.6346419566883 | Layers: [4, 64, 3], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 218.76045861016956 | Layers: [4, 256, 32, 3], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 218.8532848480475 | Layers: [4, 8, 2, 3], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 218.90263379050754 | Layers: [4, 2, 128, 3], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 219.78574695468245 | Layers: [4, 2, 3], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 219.8635009094866 | Layers: [4, 32, 3], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 220.18452393120222 | Layers: [4, 64, 3], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 233.0850677036304 | Layers: [4, 8, 2, 3], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 233.08830334790446 | Layers: [4, 256, 32, 3], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 233.12210536783402 | Layers: [4, 2, 128, 3], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 244.9059357665249 | Layers: [4, 8, 2, 3], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 244.90616359199507 | Layers: [4, 256, 32, 3], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 244.94082879821235 | Layers: [4, 2, 128, 3], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 256.68882680502713 | Layers: [4, 8, 2, 3], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 256.697979751098 | Layers: [4, 256, 32, 3], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 256.72922640644714 | Layers: [4, 2, 128, 3], Learning rate: 0.0078125, Epochs: 19\n",
      "----------4 bit average----------\n",
      "Error: 11.52125189229209 | Layers: [8, 64, 5], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 11.529966064774994 | Layers: [8, 2, 5], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 11.54941888052693 | Layers: [8, 1024, 5], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 17.734936751169116 | Layers: [8, 2, 256, 5], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 17.771136106818137 | Layers: [8, 32, 64, 5], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 17.797082005190408 | Layers: [8, 1024, 64, 5], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 22.93545220618611 | Layers: [8, 64, 5], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 22.967776082842366 | Layers: [8, 1024, 5], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 22.97390924094255 | Layers: [8, 2, 5], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 33.9142398007065 | Layers: [8, 2, 256, 5], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 34.02771311133692 | Layers: [8, 32, 64, 5], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 34.0577817867141 | Layers: [8, 1024, 64, 5], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 34.33294623164111 | Layers: [8, 2, 5], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 34.342261239293606 | Layers: [8, 64, 5], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 34.36963960349433 | Layers: [8, 1024, 5], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 49.16614492913895 | Layers: [8, 2, 256, 5], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 49.30209267643317 | Layers: [8, 32, 64, 5], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 49.30811814748233 | Layers: [8, 1024, 64, 5], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 58.8935957989017 | Layers: [8, 64, 5], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 58.92504531710621 | Layers: [8, 1024, 5], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 58.92637827094051 | Layers: [8, 2, 5], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 70.33838708906141 | Layers: [8, 64, 5], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 70.34968421794851 | Layers: [8, 1024, 5], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 70.35456700750983 | Layers: [8, 2, 5], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 70.75109544335368 | Layers: [8, 2, 256, 5], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 70.92238149223809 | Layers: [8, 1024, 64, 5], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 70.9801946945552 | Layers: [8, 32, 64, 5], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 81.71487172990274 | Layers: [8, 1024, 5], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 81.73138779396906 | Layers: [8, 2, 5], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 81.73276581717343 | Layers: [8, 64, 5], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 87.45131816332153 | Layers: [8, 2, 256, 5], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 87.64727811343163 | Layers: [8, 1024, 64, 5], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 87.77962378772474 | Layers: [8, 32, 64, 5], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 93.16559847966866 | Layers: [8, 64, 5], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 93.16735236149115 | Layers: [8, 1024, 5], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 93.16793356747601 | Layers: [8, 2, 5], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 101.95391871353873 | Layers: [8, 2, 256, 5], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 102.12386575454849 | Layers: [8, 1024, 64, 5], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 102.32648289307448 | Layers: [8, 32, 64, 5], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 104.56231391663331 | Layers: [8, 2, 5], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 104.57953900759362 | Layers: [8, 64, 5], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 104.5912005731964 | Layers: [8, 1024, 5], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 115.15006359436191 | Layers: [8, 2, 256, 5], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 115.31792874164447 | Layers: [8, 1024, 64, 5], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 115.50659368202157 | Layers: [8, 32, 64, 5], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 115.96445134595727 | Layers: [8, 2, 5], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 115.98371984429534 | Layers: [8, 1024, 5], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 115.99184023453832 | Layers: [8, 64, 5], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 127.49785347806456 | Layers: [8, 2, 256, 5], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 127.68401177851294 | Layers: [8, 1024, 64, 5], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 127.85026875555734 | Layers: [8, 32, 64, 5], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 127.89329930074541 | Layers: [8, 2, 5], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 127.9115630263835 | Layers: [8, 1024, 5], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 127.93042731351137 | Layers: [8, 64, 5], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 139.33035150933895 | Layers: [8, 2, 5], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 139.34028327238815 | Layers: [8, 1024, 5], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 139.34149537812715 | Layers: [8, 64, 5], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 139.598433391289 | Layers: [8, 2, 256, 5], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 139.7723689118355 | Layers: [8, 1024, 64, 5], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 139.93606760841266 | Layers: [8, 32, 64, 5], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 150.74368235413826 | Layers: [8, 2, 5], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 150.7526768603052 | Layers: [8, 1024, 5], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 150.75320844138386 | Layers: [8, 64, 5], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 158.5939875705992 | Layers: [8, 2, 256, 5], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 158.71044413383007 | Layers: [8, 1024, 64, 5], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 158.9317545005911 | Layers: [8, 32, 64, 5], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 162.33520600838006 | Layers: [8, 1024, 5], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 162.3383316396165 | Layers: [8, 2, 5], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 162.34599436499627 | Layers: [8, 64, 5], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 171.15776322108368 | Layers: [8, 2, 256, 5], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 171.2657461547688 | Layers: [8, 1024, 64, 5], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 171.4830373484535 | Layers: [8, 32, 64, 5], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 173.88947728970027 | Layers: [8, 1024, 5], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 173.89076122305877 | Layers: [8, 2, 5], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 173.9050209233364 | Layers: [8, 64, 5], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 183.10458432058851 | Layers: [8, 2, 256, 5], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 183.21914795447057 | Layers: [8, 1024, 64, 5], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 183.42720014823547 | Layers: [8, 32, 64, 5], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 185.42621551269244 | Layers: [8, 2, 5], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 185.4284149542269 | Layers: [8, 64, 5], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 185.4323196829548 | Layers: [8, 1024, 5], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 194.95538876258487 | Layers: [8, 2, 256, 5], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 195.05903235367205 | Layers: [8, 1024, 64, 5], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 195.275598005952 | Layers: [8, 32, 64, 5], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 197.03751255324067 | Layers: [8, 64, 5], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 197.0431127978376 | Layers: [8, 2, 5], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 197.08387850590506 | Layers: [8, 1024, 5], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 206.7612545246967 | Layers: [8, 2, 256, 5], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 206.8670815335989 | Layers: [8, 1024, 64, 5], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 207.08461447212383 | Layers: [8, 32, 64, 5], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 208.59677859991683 | Layers: [8, 2, 5], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 208.61371589331148 | Layers: [8, 64, 5], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 208.64525776165507 | Layers: [8, 1024, 5], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 218.56331690251739 | Layers: [8, 2, 256, 5], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 218.66608802522924 | Layers: [8, 1024, 64, 5], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 218.8789714003368 | Layers: [8, 32, 64, 5], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 220.12947615097198 | Layers: [8, 2, 5], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 220.14211661729527 | Layers: [8, 64, 5], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 220.16636267713912 | Layers: [8, 1024, 5], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 232.85971870271743 | Layers: [8, 2, 256, 5], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 232.89934585821504 | Layers: [8, 1024, 64, 5], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 233.15487654353532 | Layers: [8, 32, 64, 5], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 244.6760387752481 | Layers: [8, 2, 256, 5], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 244.71748787139848 | Layers: [8, 1024, 64, 5], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 244.97056714409715 | Layers: [8, 32, 64, 5], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 256.4619644506755 | Layers: [8, 2, 256, 5], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 256.51416381096794 | Layers: [8, 1024, 64, 5], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 256.75921084746534 | Layers: [8, 32, 64, 5], Learning rate: 0.0078125, Epochs: 19\n",
      "----------8 bit average----------\n",
      "Error: 11.521229323451546 | Layers: [16, 64, 9], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 11.533691838686963 | Layers: [16, 4, 9], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 11.538710909627994 | Layers: [16, 16, 9], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 17.84394381019967 | Layers: [16, 16, 4, 9], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 17.892382095197604 | Layers: [16, 2, 1024, 9], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 17.897902692752506 | Layers: [16, 8, 8, 9], Learning rate: 0.001953125, Epochs: 12\n",
      "Error: 22.949767029753932 | Layers: [16, 16, 9], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 22.95176305201178 | Layers: [16, 64, 9], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 22.952783934111224 | Layers: [16, 4, 9], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 33.97633224616584 | Layers: [16, 16, 4, 9], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 34.08411727811276 | Layers: [16, 2, 1024, 9], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 34.15260251822005 | Layers: [16, 8, 8, 9], Learning rate: 0.001953125, Epochs: 15\n",
      "Error: 34.34165779423593 | Layers: [16, 4, 9], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 34.3442153155857 | Layers: [16, 64, 9], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 34.36595163827496 | Layers: [16, 16, 9], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 49.28336841395545 | Layers: [16, 16, 4, 9], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 49.396544823757026 | Layers: [16, 2, 1024, 9], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 49.4489833308342 | Layers: [16, 8, 8, 9], Learning rate: 0.001953125, Epochs: 17\n",
      "Error: 58.68838125557738 | Layers: [16, 4, 9], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 58.80934774776554 | Layers: [16, 16, 9], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 58.91206852390396 | Layers: [16, 64, 9], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 70.11343576668179 | Layers: [16, 4, 9], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 70.2554625238196 | Layers: [16, 16, 9], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 70.36119427676782 | Layers: [16, 64, 9], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 70.92250712725581 | Layers: [16, 16, 4, 9], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 70.9721325666301 | Layers: [16, 2, 1024, 9], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 71.15471631591988 | Layers: [16, 8, 8, 9], Learning rate: 0.001953125, Epochs: 5\n",
      "Error: 81.51131188130972 | Layers: [16, 4, 9], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 81.65699891004438 | Layers: [16, 16, 9], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 81.73315252184724 | Layers: [16, 64, 9], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 87.6445441072507 | Layers: [16, 16, 4, 9], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 87.69530566472521 | Layers: [16, 2, 1024, 9], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 87.90420644231963 | Layers: [16, 8, 8, 9], Learning rate: 0.001953125, Epochs: 14\n",
      "Error: 92.94985489126626 | Layers: [16, 4, 9], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 93.10357719598046 | Layers: [16, 16, 9], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 93.14276049392916 | Layers: [16, 64, 9], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 102.14690257462254 | Layers: [16, 16, 4, 9], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 102.24230579000525 | Layers: [16, 2, 1024, 9], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 102.48498699438424 | Layers: [16, 8, 8, 9], Learning rate: 0.001953125, Epochs: 19\n",
      "Error: 104.37016647523073 | Layers: [16, 4, 9], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 104.53827591826948 | Layers: [16, 16, 9], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 104.56137859455133 | Layers: [16, 64, 9], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 115.3301841532724 | Layers: [16, 16, 4, 9], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 115.41718583278373 | Layers: [16, 2, 1024, 9], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 115.65289089939871 | Layers: [16, 8, 8, 9], Learning rate: 0.00390625, Epochs: 12\n",
      "Error: 115.7750964873406 | Layers: [16, 4, 9], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 115.93554178009686 | Layers: [16, 16, 9], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 115.96603880823984 | Layers: [16, 64, 9], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 127.69793780364805 | Layers: [16, 16, 4, 9], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 127.73135871675842 | Layers: [16, 4, 9], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 127.76865061334682 | Layers: [16, 2, 1024, 9], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 127.88616699662077 | Layers: [16, 16, 9], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 127.89927159650483 | Layers: [16, 64, 9], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 127.9894712293931 | Layers: [16, 8, 8, 9], Learning rate: 0.00390625, Epochs: 15\n",
      "Error: 139.155662600671 | Layers: [16, 4, 9], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 139.30047754274102 | Layers: [16, 16, 9], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 139.31166755256427 | Layers: [16, 64, 9], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 139.7871351519717 | Layers: [16, 16, 4, 9], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 139.8654304661464 | Layers: [16, 2, 1024, 9], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 140.09032624521876 | Layers: [16, 8, 8, 9], Learning rate: 0.00390625, Epochs: 17\n",
      "Error: 150.56283082757702 | Layers: [16, 4, 9], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 150.70670167950115 | Layers: [16, 64, 9], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 150.70930907282533 | Layers: [16, 16, 9], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 158.71444239661776 | Layers: [16, 16, 4, 9], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 158.74620393624025 | Layers: [16, 2, 1024, 9], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 159.00720699850308 | Layers: [16, 8, 8, 9], Learning rate: 0.00390625, Epochs: 5\n",
      "Error: 162.1415780417807 | Layers: [16, 4, 9], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 162.25700736522091 | Layers: [16, 64, 9], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 162.28626284906977 | Layers: [16, 16, 9], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 171.25531407261107 | Layers: [16, 16, 4, 9], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 171.30158470173595 | Layers: [16, 2, 1024, 9], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 171.56217117012466 | Layers: [16, 8, 8, 9], Learning rate: 0.00390625, Epochs: 14\n",
      "Error: 173.69471502792342 | Layers: [16, 4, 9], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 173.7933712471991 | Layers: [16, 64, 9], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 173.82660236454387 | Layers: [16, 16, 9], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 183.20654294044434 | Layers: [16, 16, 4, 9], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 183.25433386616618 | Layers: [16, 2, 1024, 9], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 183.51240831735487 | Layers: [16, 8, 8, 9], Learning rate: 0.00390625, Epochs: 19\n",
      "Error: 185.23407496806226 | Layers: [16, 4, 9], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 185.3213370114951 | Layers: [16, 64, 9], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 185.34611772625107 | Layers: [16, 16, 9], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 195.0500124634933 | Layers: [16, 16, 4, 9], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 195.09699690073913 | Layers: [16, 2, 1024, 9], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 195.35945847445805 | Layers: [16, 8, 8, 9], Learning rate: 0.0078125, Epochs: 12\n",
      "Error: 196.87599335419625 | Layers: [16, 4, 9], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 196.97616873293012 | Layers: [16, 64, 9], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 196.9936408102921 | Layers: [16, 16, 9], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 206.85867192690642 | Layers: [16, 16, 4, 9], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 206.9091004805013 | Layers: [16, 2, 1024, 9], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 207.16143911811727 | Layers: [16, 8, 8, 9], Learning rate: 0.0078125, Epochs: 15\n",
      "Error: 208.4488562618683 | Layers: [16, 4, 9], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 208.53760114669166 | Layers: [16, 64, 9], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 208.57041568550474 | Layers: [16, 16, 9], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 218.65750835379973 | Layers: [16, 16, 4, 9], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 218.71361268256558 | Layers: [16, 2, 1024, 9], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 218.960900198967 | Layers: [16, 8, 8, 9], Learning rate: 0.0078125, Epochs: 17\n",
      "Error: 219.99025416238172 | Layers: [16, 4, 9], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 220.04443344359504 | Layers: [16, 64, 9], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 220.09630097405383 | Layers: [16, 16, 9], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 232.91196578365566 | Layers: [16, 16, 4, 9], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 232.96017903141293 | Layers: [16, 2, 1024, 9], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 233.2478435373495 | Layers: [16, 8, 8, 9], Learning rate: 0.0078125, Epochs: 5\n",
      "Error: 244.7329663853673 | Layers: [16, 16, 4, 9], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 244.77259000372746 | Layers: [16, 2, 1024, 9], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 245.0663715486289 | Layers: [16, 8, 8, 9], Learning rate: 0.0078125, Epochs: 14\n",
      "Error: 256.52539348656046 | Layers: [16, 16, 4, 9], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 256.56037012506084 | Layers: [16, 2, 1024, 9], Learning rate: 0.0078125, Epochs: 19\n",
      "Error: 256.85776392782293 | Layers: [16, 8, 8, 9], Learning rate: 0.0078125, Epochs: 19\n"
     ]
    }
   ],
   "source": [
    "print('----------2 bit average----------')\n",
    "print_performance_dict(average_performance_dict_2bits)\n",
    "print('----------4 bit average----------')\n",
    "print_performance_dict(average_performance_dict_4bits)\n",
    "print('----------8 bit average----------')\n",
    "print_performance_dict(average_performance_dict_8bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf111c91-cfaf-4293-b004-0b1b0014e768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the average performance data\n",
    "performance_dicts = [average_performance_dict_2bits, average_performance_dict_4bits, average_performance_dict_8bits]\n",
    "for i in range(len(performance_dicts)):\n",
    "    with open(f'./data/{2**(i+1)}bit_average_performance.txt', 'w') as f:\n",
    "        f.write('parameters,performance\\n')\n",
    "        f.writelines([f'{x}\\n' for x in sorted(list(performance_dicts[i].items()), key=lambda x: x[1], reverse=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c0ca12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step from index 0\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 3\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 6\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 9\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 12\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 15\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "{208, 209}\n",
      "-----------------------------------\n",
      "Step from index 18\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 21\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 24\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 27\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 30\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "{184, 183}\n",
      "-----------------------------------\n",
      "Step from index 33\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 36\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "{171, 172}\n",
      "-----------------------------------\n",
      "Step from index 39\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 42\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 45\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 48\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 51\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 54\n",
      "All layers in step the unique\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 57\n",
      "All layers in step the unique\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 60\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 63\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "{115, 116}\n",
      "-----------------------------------\n",
      "Step from index 66\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "{104, 105}\n",
      "-----------------------------------\n",
      "Step from index 69\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 72\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 75\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 78\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 81\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 84\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 87\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 90\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 93\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 96\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 99\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 102\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n",
      "Step from index 105\n",
      "All layers in step the unique\n",
      "All epochs in step the same\n",
      "All lr in step the same\n",
      "All err within round\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check whether the average data goes by steps for each network\n",
    "from csv import reader\n",
    "\n",
    "with open ('./data/8bit_average_performance.txt', 'r') as f:\n",
    "    csv_reader = reader(f, delimiter=',')\n",
    "    network_params =  []\n",
    "    \n",
    "    skip = True\n",
    "    for row in csv_reader:\n",
    "        if skip: skip = False; continue\n",
    "        \n",
    "        if len(row)==6:\n",
    "            network_params.append({'layers': row[0]+row[1]+row[2], 'lr': row[3], 'epochs': row[4], 'error': float(row[5][1:-1])})\n",
    "        \n",
    "        if len(row)==7:\n",
    "            network_params.append({'layers': row[0]+row[1]+row[2]+row[3], 'lr': row[4], 'epochs': row[5], 'error': float(row[6][1:-1])})\n",
    "    \n",
    "    for i in range(0, len(network_params), 3):\n",
    "        layers_steps = [network_params[i]['layers'], \n",
    "                       network_params[i+1]['layers'], \n",
    "                       network_params[i+2]['layers']]\n",
    "        \n",
    "        epochs_steps = [network_params[i]['epochs'], \n",
    "                       network_params[i+1]['epochs'], \n",
    "                       network_params[i+2]['epochs']]\n",
    "        \n",
    "        lr_steps = [network_params[i]['lr'], \n",
    "                       network_params[i+1]['lr'], \n",
    "                       network_params[i+2]['lr']]\n",
    "        \n",
    "        err_steps = [round(network_params[i]['error']), \n",
    "                       round(network_params[i+1]['error']), \n",
    "                       round(network_params[i+2]['error'])]\n",
    "        \n",
    "        print(f'Step from index {i}')\n",
    "        \n",
    "        if len(layers_steps) == len(set(layers_steps)):\n",
    "            print('All layers in step the unique')\n",
    "        \n",
    "        if 1 == len(set(epochs_steps)):\n",
    "            print('All epochs in step the same')\n",
    "            \n",
    "        if 1 == len(set(lr_steps)):\n",
    "            print('All lr in step the same')\n",
    "        \n",
    "        if 1 == len(set(err_steps)):\n",
    "            print('All err within round')\n",
    "        else: print(set(err_steps))\n",
    "            \n",
    "        print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ac04ca1e-3c6b-40af-b6b7-99cb032265f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: test extremely simplified network structures see beneath as well\n",
    "# TODO: test an extremely complexe network structure (just a lot of layers)\n",
    "# TODO: test stable network for whole range of epochs and record results\n",
    "# TODO: test stable network performance on hard lim transfer functions\n",
    "# TODO: test stable network performance but training it with a hardlim transfer function last layer\n",
    "# TODO: redo all this with symetrical network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "26a62729-863e-4263-8d9c-4d66e90bc36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test performance on an extremely simple network structure\n",
    "# Network parameters\n",
    "R = 4\n",
    "layer_sizes = [4, 8, 2]\n",
    "deriv_transfer_functions = [deriv_logsig, deriv_lin]\n",
    "# Inputs and outputs\n",
    "inputs, outputs, S = gen_inputs_outputs(R)\n",
    "layer_sizes = np.array(layer_sizes + [S], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "34b03a57-3b04-4a24-844e-a6c5cc655fd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m reset_params()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_network\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.001953125\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(performance())\n",
      "Cell \u001b[0;32mIn[20], line 13\u001b[0m, in \u001b[0;36mtrain_network\u001b[0;34m(learning_rate, epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Iterate through the inputs and outputs\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs)):\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;66;03m# Run the network\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m         \u001b[43mrun_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_sizes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m# Get the dialation matrix for the last layer\u001b[39;00m\n\u001b[1;32m     16\u001b[0m         F_dot \u001b[38;5;241m=\u001b[39m fill_F_dot(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 14\u001b[0m, in \u001b[0;36mrun_network\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(weights_list)):\n\u001b[1;32m     13\u001b[0m     n_list[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmatmul(weights_list[i], a_list[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m+\u001b[39m biases_list[i]\n\u001b[0;32m---> 14\u001b[0m     a_list[i] \u001b[38;5;241m=\u001b[39m \u001b[43mtransfer_functions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m(n_list[i])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "reset_params()\n",
    "train_network(0.001953125, epochs=12)\n",
    "print(performance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bd1f488c-f7ce-4248-9ad2-cc572723d087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test performance on an extremely complexe network structure\n",
    "# Network parameters\n",
    "R = 4\n",
    "layer_sizes = [4, 1024, 1024, 1024, 1024]\n",
    "transfer_functions = [logsig, logsig, logsig, logsig, lin]\n",
    "deriv_transfer_functions = [deriv_logsig, deriv_logsig, deriv_logsig, deriv_logsig, deriv_lin]\n",
    "# Inputs and outputs\n",
    "inputs, outputs, S = gen_inputs_outputs(R)\n",
    "layer_sizes = np.array(layer_sizes + [S], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "92dfc2b5-c9df-4bf2-bcd8-e6cda2fdd5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2955718257616284e+190\n"
     ]
    }
   ],
   "source": [
    "reset_params()\n",
    "train_network(0.001953125, epochs=12)\n",
    "print(performance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5649a34f-a7ad-463a-9402-b72e5a9e3c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18f00e57-ffe2-4019-befa-371b308d4aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(layer_sizes[1], input_shape=(layer_sizes[0],), activation='sigmoid'))\n",
    "model.add(Dense(layer_sizes[2], activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1461c9e-d5ff-46f6-bf5d-d3d912900cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.5000 - loss: 7.0425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1672a4dd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdg = SGD(.9)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=sdg,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "model.fit(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94cda203-692a-464f-a3e4-0ef7c23a265e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.01186371, -8.282264  , -1.4656483 ],\n",
       "       [ 0.0887537 , -9.469966  , -1.5549538 ],\n",
       "       [ 0.15937938, -8.323184  , -1.3819622 ],\n",
       "       [ 0.22767666, -9.4916    , -1.4718292 ],\n",
       "       [-0.01628557, -8.611647  , -1.6199257 ],\n",
       "       [ 0.04203045, -9.72632   , -1.6907108 ],\n",
       "       [ 0.14307892, -8.662352  , -1.5352875 ],\n",
       "       [ 0.20412186, -9.765932  , -1.603532  ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow25",
   "language": "python",
   "name": "tensorflow25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
