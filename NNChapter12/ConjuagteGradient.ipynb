{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17d0953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sys import path\n",
    "path.append('../tools')\n",
    "from tools import logsig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c737cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expected_output(X):\n",
    "    return logsig(np.dot(logsig(X * np.array([10, 10]) + np.array([-5, 5])), np.array([1, 1])) + -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5704f28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_get_y = np.vectorize(get_expected_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91245844",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.linspace(-2, 2, 82)\n",
    "y_train = vec_get_y(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed880644",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(len(x_train), 1)\n",
    "y_train = y_train.reshape(len(y_train), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "206c490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with keras and tensorflow\n",
    "# Adapted from : https://keras.io/guides/custom_train_step_in_tensorflow/\n",
    "\n",
    "#Imports. Need to do this for some reason\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "afe8c7e2-4d97-49ca-8cc8-db7d76fc91eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.search_direction = None\n",
    "        self.beta = None\n",
    "        self.old_flattened_gradients = None\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        self.optimizer.learning_rate.assign(.1)\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        x, y = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            loss = self.compute_loss(y=y, y_pred=y_pred)\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        flattened_gradients = tf.concat([tf.reshape(gradient, [-1]) for gradient in gradients], 0)\n",
    "\n",
    "        if self.search_direction is None:\n",
    "            self.search_direction = -gradients\n",
    "            self.flattened_search_direction = -flattened_gradients\n",
    "            self.old_flattened_gradients = -flattened_gradients\n",
    "        else:\n",
    "            self.beta = \n",
    "\n",
    "        # Find interval for the best learning rate\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply(-self.search_direction, trainable_vars)\n",
    "\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        for metric in self.metrics:\n",
    "            if metric.name == \"loss\":\n",
    "                metric.update_state(loss)\n",
    "            else:\n",
    "                metric.update_state(y, y_pred)\n",
    "\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0726cf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "None\n",
      "Tensor(\"concat:0\", shape=(7,), dtype=float32)\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 0.3984\n",
      "Epoch 2/3\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 0.0059\n",
      "Epoch 3/3\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 0.0031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17e8d97d0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct and compile an instance of CustomModel\n",
    "inputs = keras.Input(shape=(1,))\n",
    "x = keras.layers.Dense(2)(inputs)\n",
    "outputs = keras.layers.Dense(1)(x)\n",
    "model = CustomModel(inputs, outputs)\n",
    "model.compile(optimizer=\"SGD\", loss=\"mse\")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4048a136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba0c68-e57b-43aa-9889-b62f12fcff8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tm",
   "language": "python",
   "name": "tm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
